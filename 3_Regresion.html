
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Modelo de Regresión Lineal &#8212; Microeconometria Aplicada</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '3_Regresion';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Modelo de Regresión Multiple" href="4_Regresion.html" />
    <link rel="prev" title="Qué es la Microeconometría?" href="0_Motivacion.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Microeconometria Aplicada - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Microeconometria Aplicada - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Microeconometría Aplicada
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="0_Motivacion.html">Qué es la Microeconometría?</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Modelo de Regresión Lineal</a></li>
<li class="toctree-l1"><a class="reference internal" href="4_Regresion.html">Modelo de Regresión Multiple</a></li>
<li class="toctree-l1"><a class="reference internal" href="5_Supuestos.html">Evaluación de Supuestos</a></li>
<li class="toctree-l1"><a class="reference internal" href="6_Respuesta_Cualitativa.html">Variables de Respuesta Cualitativa</a></li>

<li class="toctree-l1"><a class="reference internal" href="7_RepeatedCross.html">Modelo de Cortes Transversales Repetidos</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_Probabilidad.html">Fundamentos de Probabilidad</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_Estadistica.html">Fundamentos de Estadística</a></li>
<li class="toctree-l1"><a class="reference internal" href="Taller_1_Sol.html">Taller 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="Taller_2_Sol.html">Taller 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="Taller_3_Sol.html">Taller 3</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2F3_Regresion.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/3_Regresion.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Modelo de Regresión Lineal</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-simple-o-univariada">Regresión Simple o Univariada</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supuestos-del-modelo">Supuestos del Modelo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linealidad-en-parametros">Linealidad en Parámetros</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#no-multicolinealidad-o-rango-completo">No Multicolinealidad o Rango Completo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#homoscedasticidad">Homoscedasticidad</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#no-autocorrelacion">No Autocorrelación</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distribucion-normal-de-los-errores">Distribución Normal de los Errores</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#independencia-condicional-o-exogenidad">Independencia Condicional o Exogenidad</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#minimos-cuadrados-ordinarios-mco">Mínimos Cuadrados Ordinarios (MCO)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicacion-relacion-entre-aprendizaje-y-recursos-economicos">Aplicacion : Relación entre Aprendizaje y Recursos Económicos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#residuales-de-la-regresion-e-i-y-i-hat-y-i">Residuales de la Regresión: <span class="math notranslate nohighlight">\(e_i = Y_i - \hat Y_i\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#propiedades-de-los-estimadores-hat-beta-k">Propiedades de los estimadores <span class="math notranslate nohighlight">\(\hat\beta_k\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inferencia-en-regresion-simple">Inferencia en Regresión Simple</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pruebas-de-hipotesis-sobre-hat-beta-k">Pruebas de Hipótesis sobre <span class="math notranslate nohighlight">\(\hat\beta_k\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#varianza-de-hat-beta-k">Varianza de <span class="math notranslate nohighlight">\(\hat\beta_k\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#varianza-de-los-errores">Varianza de los Errores</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pruebas-de-hipotesis-individuales">Pruebas de Hipótesis Individuales</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#intervalo-de-confianza-para-beta-k">Intervalo de confianza para <span class="math notranslate nohighlight">\(\beta_k\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#coeficiente-de-determinacion-r-2">Coeficiente de Determinación: <span class="math notranslate nohighlight">\(R^2\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prueba-de-significancia-global">Prueba de Significancia Global</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prediccion-e-inferencia-para-hat-y-i">Predicción e Inferencia para <span class="math notranslate nohighlight">\(\hat Y_i\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prediccion-media">Predicción Media</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prediccion-individual">Predicción Individual</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicacion">Aplicación:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-de-coeficientes">Interpretación de Coeficientes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lin-lin">Lin-Lin</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#log-lin">Log-Lin</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lin-log">Lin-Log</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#log-log">Log-Log</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimacion-por-maxima-verosimilitud">Estimación por Máxima Verosimilitud</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="modelo-de-regresion-lineal">
<h1>Modelo de Regresión Lineal<a class="headerlink" href="#modelo-de-regresion-lineal" title="Link to this heading">#</a></h1>
<p>La regresion es un método que nos permite estudiar la relación entre una variable de resultado <span class="math notranslate nohighlight">\(Y\)</span> y una covariable o predictor <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>La función de regresión, <span class="math notranslate nohighlight">\(r(X)\)</span>, resume la relación entre <span class="math notranslate nohighlight">\(X\)</span> y <span class="math notranslate nohighlight">\(Y\)</span>:</p>
<div class="math notranslate nohighlight">
\[
r(x) = \mathbb{E}(Y | X = x) = \int y f(y|x) dy.
\]</div>
<p>Nuestro objetivo es estimar <span class="math notranslate nohighlight">\(r(x)\)</span> usando datos de la forma</p>
<div class="math notranslate nohighlight">
\[\{Y_i , X_i\}_{i = 1}^n\]</div>
<p>Definamos el error <span class="math notranslate nohighlight">\(\varepsilon = Y - r(x)\)</span>. De esta manera, podemos escribir:</p>
<div class="math notranslate nohighlight">
\[
Y = r(x) + \varepsilon
\]</div>
<section id="regresion-simple-o-univariada">
<h2>Regresión Simple o Univariada<a class="headerlink" href="#regresion-simple-o-univariada" title="Link to this heading">#</a></h2>
<p>En su versión más simple, <span class="math notranslate nohighlight">\(X\)</span> es unidimensional y asumimos que <span class="math notranslate nohighlight">\(r(x)\)</span> es lineal. Así,</p>
<div class="math notranslate nohighlight">
\[r(x) = \beta_0 + \beta_1 x.\]</div>
<p>El modelo regresión lineal simple se define como:</p>
<div class="math notranslate nohighlight">
\[
Y_i = r(x) + \varepsilon_i = \beta_0 + \beta_1 X_i + \varepsilon_i
\]</div>
<p>Observe que los parámetros desconocidos en este modelo son el intercepto <span class="math notranslate nohighlight">\(\beta_0\)</span> y la pendiente <span class="math notranslate nohighlight">\(\beta_1\)</span>.</p>
<div class="alert alert-block alert-warning"> 
<b>EJEMPLO:</b>
<p>
<p>La función de demanda inversa establece la relación entre precios <span class="math notranslate nohighlight">\(P_i\)</span> y cantidades <span class="math notranslate nohighlight">\(Q_i\)</span>. Esta relación la podemos estimar a partir de una modelo de la forma:</p>
<div class="math notranslate nohighlight">
\[P_i = \alpha + \beta \cdot Q_i + u_i\]</div>
<p>Quisieramos probar la siguiente hipótesis:</p>
<div class="math notranslate nohighlight">
\[H_0: \beta &lt; 0\]</div>
<div class="math notranslate nohighlight">
\[H_1: \beta \geq 0\]</div>
</div></section>
<section id="supuestos-del-modelo">
<h2>Supuestos del Modelo<a class="headerlink" href="#supuestos-del-modelo" title="Link to this heading">#</a></h2>
<p>Para estimar el modelo de regresión suponemos:</p>
<ul class="simple">
<li><p>Linealidad en los parámetros</p></li>
<li><p>No multicolinealidad o Rango Completo</p></li>
<li><p>Homoscedasticidad</p></li>
<li><p>No autocorrelación</p></li>
<li><p>Distribución Normal de los Errores</p></li>
<li><p>Independencia Condicional o Exogenidad</p></li>
</ul>
<p>Algunos de estos supuestos hace que el modelo sea <strong>estimable</strong>, otros nos permiten hacer <strong>inferencia</strong> sobre los parámetros</p>
</section>
<section id="linealidad-en-parametros">
<h2>Linealidad en Parámetros<a class="headerlink" href="#linealidad-en-parametros" title="Link to this heading">#</a></h2>
<p>Este supuesto es necesario para que el modelo sea <strong>estimable</strong>.</p>
<p>Se refiere a la forma funcional de la función de regresión <span class="math notranslate nohighlight">\(r(x) = \beta_0 + \beta_1 X_i\)</span>.</p>
<p>Note que nos interesa estimar <span class="math notranslate nohighlight">\(\beta_k\)</span>, no <span class="math notranslate nohighlight">\(\beta_k^2\)</span>, <span class="math notranslate nohighlight">\(\ln(\beta_k)\)</span>, o cualquier otra función <span class="math notranslate nohighlight">\(g(\beta_k)\)</span>.</p>
<div class="alert alert-block alert-warning"> 
<b>EJEMPLO:</b>
<p>
<p>Suponga queremos estimar el parámetro <span class="math notranslate nohighlight">\(\beta\)</span> de la función <span class="math notranslate nohighlight">\(y = A X^\beta e^\varepsilon\)</span>. ¿Podemos usar el modelo de regresión lineal?</p>
<p>Sí, note que podemos utilizar la siguiente transformación:</p>
<div class="math notranslate nohighlight">
\[\ln y_i = \alpha + \beta \cdot X_i + \varepsilon_i, \text{ con } \alpha = \ln A\]</div>
<p>¿Qué pasa si <span class="math notranslate nohighlight">\(y = A X^\beta e^\varepsilon + u\)</span> ?</p>
</div></section>
<section id="no-multicolinealidad-o-rango-completo">
<h2>No Multicolinealidad o Rango Completo<a class="headerlink" href="#no-multicolinealidad-o-rango-completo" title="Link to this heading">#</a></h2>
<p>Este supuesto es necesario para que el modelo sea <strong>estimable</strong>.</p>
<p>El supuesto hace referencia a la información que aportan diferentes covariables. En primer lugar, este supuesto señala que:</p>
<div class="math notranslate nohighlight">
\[|\rho(X_{1i}, X_{2i})| \neq 1\]</div>
<p>Donde <span class="math notranslate nohighlight">\(\rho\)</span> es el coeficiente de correlación. Este supuesto será más relevante cuando estudiemos el modelo de regresión múltiple.</p>
<p>Adicionalmente, es necesario que el número de observaciones en los datos <span class="math notranslate nohighlight">\(n\)</span> sea mayor al número de parámetros <span class="math notranslate nohighlight">\(k\)</span> que queremos estimar. Es decir</p>
<div class="math notranslate nohighlight">
\[n \geq k\]</div>
</section>
<section id="homoscedasticidad">
<h2>Homoscedasticidad<a class="headerlink" href="#homoscedasticidad" title="Link to this heading">#</a></h2>
<p>Este supuesto es sobre la varianza y nos facilita realizar pruebas de hipótesis</p>
<p>El supuesto establece que:</p>
<div class="math notranslate nohighlight">
\[V(\varepsilon_i | X) = \sigma^2\]</div>
<p>La violación de este supuesto se conoce como <strong>heteroscedasticidad</strong>. En un modelo <strong>heteroscedástico</strong></p>
<div class="math notranslate nohighlight">
\[V(\varepsilon_i | X) = \sigma_i^2\]</div>
</section>
<section id="no-autocorrelacion">
<h2>No Autocorrelación<a class="headerlink" href="#no-autocorrelacion" title="Link to this heading">#</a></h2>
<p>Este supuesto establece que:</p>
<div class="math notranslate nohighlight">
\[Cov(\varepsilon_i, \varepsilon_j | X) = 0 \text{ para todo } i \neq j\]</div>
<p>La violación de este supuesto se conoce como <strong>autocorrelación</strong>.</p>
</section>
<section id="distribucion-normal-de-los-errores">
<h2>Distribución Normal de los Errores<a class="headerlink" href="#distribucion-normal-de-los-errores" title="Link to this heading">#</a></h2>
<p>Este supuesto se hace sobre los errores entonces también afecta las pruebas de hipótesis.</p>
<p>El supuesto señala que:</p>
<div class="math notranslate nohighlight">
\[\varepsilon_i | X \sim N(0, \sigma^2)\]</div>
<p>Observe que por el teorema del límite central este supuesto no es tan fuerte, y si muy útil para determinar cómo se distribuyen ciertos estadísticos.</p>
</section>
<section id="independencia-condicional-o-exogenidad">
<h2>Independencia Condicional o Exogenidad<a class="headerlink" href="#independencia-condicional-o-exogenidad" title="Link to this heading">#</a></h2>
<p>Para que los estimadores de <span class="math notranslate nohighlight">\(\beta_k\)</span> sean insesgados y consistentes suponemos que</p>
<div class="math notranslate nohighlight">
\[E(\varepsilon_i | X) = E(\varepsilon_i)\]</div>
<p>Observe que combinado con el supuesto anterior tenemos que:</p>
<div class="math notranslate nohighlight">
\[E(\varepsilon_i | X) = 0\]</div>
<p>Según este supuesto <span class="math notranslate nohighlight">\(\varepsilon\)</span> es indepente de <span class="math notranslate nohighlight">\(X\)</span>. En otras palabras <span class="math notranslate nohighlight">\(X\)</span> es una variable exogena.</p>
<p>Este supuesto garantiza que los efectos encontrados pueden se interpretados como estimaciones <strong>causales</strong>.</p>
</section>
<section id="minimos-cuadrados-ordinarios-mco">
<h2>Mínimos Cuadrados Ordinarios (MCO)<a class="headerlink" href="#minimos-cuadrados-ordinarios-mco" title="Link to this heading">#</a></h2>
<p>Para estimar <span class="math notranslate nohighlight">\(\beta_0\)</span> y <span class="math notranslate nohighlight">\(\beta_1\)</span> podemos usar el método MCO, de manera formal:</p>
<div class="math notranslate nohighlight">
\[\{\hat\beta_0, \hat\beta_1\} = \operatorname*{arg\,min} \mathcal{L}(\beta_0, \beta_1)\]</div>
<p>donde <span class="math notranslate nohighlight">\(\mathcal{L}(\beta_0, \beta_1) = \sum_i {\varepsilon_i}^2 = \sum_i ({Y_i} - \beta_0 - \beta_1 X_i)^2\)</span></p>
<p>Las condiciones de primer orden (CPO) de este problema estan dadas por:</p>
<div class="math notranslate nohighlight">
\[\frac{\partial\mathcal{L}}{\partial\beta_0} \bigg|_{(\hat\beta_0, \hat\beta_1)} = \sum_i (-2) \cdot ({Y_i} - \beta_0 - \beta_1 X_i) \bigg|_{(\hat\beta_0, \hat\beta_1)} = 0\]</div>
<div class="math notranslate nohighlight">
\[\frac{\partial\mathcal{L}}{\partial\beta_1} \bigg|_{(\hat\beta_0, \hat\beta_1)} = \sum_i (-2 X_i) \cdot ({Y_i} - \beta_0 - \beta_1 X_i) \bigg|_{(\hat\beta_0, \hat\beta_1)} = 0\]</div>
<p>Estas ecuaciones se conocen como <strong>ecuaciones normales</strong>.</p>
<p>A partir de estas condiciones obtenemos los siguientes <strong>estimadores</strong>:</p>
<div class="math notranslate nohighlight">
\[\hat\beta_0 = \overline Y - \hat\beta_1 \overline X\]</div>
<div class="math notranslate nohighlight">
\[\hat\beta_1 = \frac{\sum_i (X_i - \overline X)(Y_i - \overline Y)}{\sum_i (X_i - \overline X)^2} = \frac{\mathbb{\hat Cov}(X, Y)}{\mathbb{\hat V}(X)}\]</div>
<p>De esta manera, la <strong>linea ajustada</strong> está dada por <span class="math notranslate nohighlight">\(\hat r(x) = \hat\beta_0 + \hat\beta_1 x\)</span>, y los <strong>valores predichos</strong> se definen como <span class="math notranslate nohighlight">\(\hat Y_i = \hat r(X_i)\)</span></p>
<p>Definimos además el <strong>residual</strong> como $<span class="math notranslate nohighlight">\(e_i = Y_i - \hat Y_i = Y_i - \left(\hat\beta_0 + \hat\beta_1 X_i \right)\)</span>$</p>
</section>
<section id="aplicacion-relacion-entre-aprendizaje-y-recursos-economicos">
<h2>Aplicacion : Relación entre Aprendizaje y Recursos Económicos<a class="headerlink" href="#aplicacion-relacion-entre-aprendizaje-y-recursos-economicos" title="Link to this heading">#</a></h2>
<p>Vamos a usar datos de las pruebas PISA, que toman estudiantes de 15 años de diversos paises, para estudiar la relación entre aprendizaje y recursos económicos</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">datos</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span>
<span class="w">  </span><span class="n">cnt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;ALB&quot;</span><span class="p">,</span><span class="s">&quot;ARE&quot;</span><span class="p">,</span><span class="s">&quot;ARG&quot;</span><span class="p">,</span><span class="s">&quot;AUS&quot;</span><span class="p">,</span><span class="s">&quot;AUT&quot;</span><span class="p">,</span><span class="s">&quot;BEL&quot;</span><span class="p">,</span><span class="s">&quot;BGR&quot;</span><span class="p">,</span><span class="s">&quot;BRA&quot;</span><span class="p">,</span><span class="s">&quot;BRN&quot;</span><span class="p">,</span><span class="s">&quot;CAN&quot;</span><span class="p">,</span><span class="s">&quot;CHE&quot;</span><span class="p">,</span><span class="s">&quot;CHL&quot;</span><span class="p">,</span><span class="s">&quot;COL&quot;</span><span class="p">,</span><span class="s">&quot;CRI&quot;</span><span class="p">,</span><span class="s">&quot;CZE&quot;</span><span class="p">,</span><span class="s">&quot;DEU&quot;</span><span class="p">,</span><span class="s">&quot;DNK&quot;</span><span class="p">,</span><span class="s">&quot;DOM&quot;</span><span class="p">,</span><span class="s">&quot;ESP&quot;</span><span class="p">,</span><span class="s">&quot;EST&quot;</span><span class="p">,</span><span class="s">&quot;FIN&quot;</span><span class="p">,</span><span class="s">&quot;FRA&quot;</span><span class="p">,</span><span class="s">&quot;GBR&quot;</span><span class="p">,</span><span class="s">&quot;GEO&quot;</span><span class="p">,</span><span class="s">&quot;GRC&quot;</span><span class="p">,</span><span class="s">&quot;GTM&quot;</span><span class="p">,</span><span class="s">&quot;HKG&quot;</span><span class="p">,</span><span class="s">&quot;HRV&quot;</span><span class="p">,</span><span class="s">&quot;HUN&quot;</span><span class="p">,</span><span class="s">&quot;IDN&quot;</span><span class="p">,</span><span class="s">&quot;IRL&quot;</span><span class="p">,</span><span class="s">&quot;ISL&quot;</span><span class="p">,</span><span class="s">&quot;ISR&quot;</span><span class="p">,</span><span class="s">&quot;ITA&quot;</span><span class="p">,</span><span class="s">&quot;JAM&quot;</span><span class="p">,</span><span class="s">&quot;JOR&quot;</span><span class="p">,</span><span class="s">&quot;JPN&quot;</span><span class="p">,</span><span class="s">&quot;KAZ&quot;</span><span class="p">,</span><span class="s">&quot;KHM&quot;</span><span class="p">,</span><span class="s">&quot;KOR&quot;</span><span class="p">,</span><span class="s">&quot;KSV&quot;</span><span class="p">,</span><span class="s">&quot;LTU&quot;</span><span class="p">,</span><span class="s">&quot;LVA&quot;</span><span class="p">,</span><span class="s">&quot;MAC&quot;</span><span class="p">,</span><span class="s">&quot;MAR&quot;</span><span class="p">,</span><span class="s">&quot;MDA&quot;</span><span class="p">,</span><span class="s">&quot;MEX&quot;</span><span class="p">,</span><span class="s">&quot;MKD&quot;</span><span class="p">,</span><span class="s">&quot;MLT&quot;</span><span class="p">,</span><span class="s">&quot;MNE&quot;</span><span class="p">,</span><span class="s">&quot;MNG&quot;</span><span class="p">,</span><span class="s">&quot;MYS&quot;</span><span class="p">,</span><span class="s">&quot;NLD&quot;</span><span class="p">,</span><span class="s">&quot;NOR&quot;</span><span class="p">,</span><span class="s">&quot;NZL&quot;</span><span class="p">,</span><span class="s">&quot;PAN&quot;</span><span class="p">,</span><span class="s">&quot;PER&quot;</span><span class="p">,</span><span class="s">&quot;PHL&quot;</span><span class="p">,</span><span class="s">&quot;POL&quot;</span><span class="p">,</span><span class="s">&quot;PRT&quot;</span><span class="p">,</span><span class="s">&quot;PRY&quot;</span><span class="p">,</span><span class="s">&quot;PSE&quot;</span><span class="p">,</span><span class="s">&quot;QAT&quot;</span><span class="p">,</span><span class="s">&quot;QAZ&quot;</span><span class="p">,</span><span class="s">&quot;QUR&quot;</span><span class="p">,</span><span class="s">&quot;ROU&quot;</span><span class="p">,</span><span class="s">&quot;SAU&quot;</span><span class="p">,</span><span class="s">&quot;SGP&quot;</span><span class="p">,</span><span class="s">&quot;SLV&quot;</span><span class="p">,</span><span class="s">&quot;SRB&quot;</span><span class="p">,</span><span class="s">&quot;SVK&quot;</span><span class="p">,</span><span class="s">&quot;SVN&quot;</span><span class="p">,</span><span class="s">&quot;SWE&quot;</span><span class="p">,</span><span class="s">&quot;TAP&quot;</span><span class="p">,</span><span class="s">&quot;THA&quot;</span><span class="p">,</span><span class="s">&quot;TUR&quot;</span><span class="p">,</span><span class="s">&quot;URY&quot;</span><span class="p">,</span><span class="s">&quot;USA&quot;</span><span class="p">,</span><span class="s">&quot;UZB&quot;</span><span class="p">,</span><span class="s">&quot;VNM&quot;</span><span class="p">),</span>
<span class="w">  </span><span class="n">math</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">368.25405</span><span class="p">,</span><span class="m">433.82986</span><span class="p">,</span><span class="m">388.54898</span><span class="p">,</span><span class="m">487.16594</span><span class="p">,</span><span class="m">490.87702</span><span class="p">,</span><span class="m">494.01554</span><span class="p">,</span><span class="m">418.33838</span><span class="p">,</span><span class="m">381.13655</span><span class="p">,</span><span class="m">440.66541</span><span class="p">,</span><span class="m">484.52203</span><span class="p">,</span><span class="m">506.45947</span><span class="p">,</span><span class="m">428.55602</span><span class="p">,</span><span class="m">390.80082</span><span class="p">,</span><span class="m">384.34594</span><span class="p">,</span><span class="m">499.37027</span><span class="p">,</span><span class="m">477.74352</span><span class="p">,</span><span class="m">478.7986</span><span class="p">,</span><span class="m">339.82878</span><span class="p">,</span><span class="m">481.86548</span><span class="p">,</span><span class="m">512.71336</span><span class="p">,</span><span class="m">475.32395</span><span class="p">,</span><span class="m">468.24401</span><span class="p">,</span><span class="m">481.82223</span><span class="p">,</span><span class="m">390.46145</span><span class="p">,</span><span class="m">433.54079</span><span class="p">,</span><span class="m">345.55713</span><span class="p">,</span><span class="m">546.03005</span><span class="p">,</span><span class="m">462.98476</span><span class="p">,</span><span class="m">479.72656</span><span class="p">,</span><span class="m">379.03128</span><span class="p">,</span><span class="m">492.17959</span><span class="p">,</span><span class="m">459.27331</span><span class="p">,</span><span class="m">457.12382</span><span class="p">,</span><span class="m">474.03372</span><span class="p">,</span><span class="m">371.40991</span><span class="p">,</span><span class="m">360.30719</span><span class="p">,</span><span class="m">534.92948</span><span class="p">,</span><span class="m">446.01273</span><span class="p">,</span><span class="m">327.40929</span><span class="p">,</span><span class="m">531.09303</span><span class="p">,</span><span class="m">352.41048</span><span class="p">,</span><span class="m">471.54378</span><span class="p">,</span><span class="m">482.58027</span><span class="p">,</span><span class="m">552.05427</span><span class="p">,</span><span class="m">363.36233</span><span class="p">,</span><span class="m">415.52394</span><span class="p">,</span><span class="m">395.40581</span><span class="p">,</span><span class="m">390.49863</span><span class="p">,</span><span class="m">468.9976</span><span class="p">,</span><span class="m">406.00521</span><span class="p">,</span><span class="m">423.92532</span><span class="p">,</span><span class="m">409.49151</span><span class="p">,</span><span class="m">491.04093</span><span class="p">,</span><span class="m">468.47831</span><span class="p">,</span><span class="m">478.87437</span><span class="p">,</span><span class="m">353.49833</span><span class="p">,</span><span class="m">394.15257</span><span class="p">,</span><span class="m">354.16683</span><span class="p">,</span><span class="m">494.4546</span><span class="p">,</span><span class="m">475.57748</span><span class="p">,</span><span class="m">340.78028</span><span class="p">,</span><span class="m">364.66173</span><span class="p">,</span><span class="m">411.98931</span><span class="p">,</span><span class="m">398.33636</span><span class="p">,</span><span class="m">444.34014</span><span class="p">,</span><span class="m">435.55027</span><span class="p">,</span><span class="m">389.20505</span><span class="p">,</span><span class="m">573.98391</span><span class="p">,</span><span class="m">345.12158</span><span class="p">,</span><span class="m">439.81693</span><span class="p">,</span><span class="m">468.62039</span><span class="p">,</span><span class="m">471.70524</span><span class="p">,</span><span class="m">482.4206</span><span class="p">,</span><span class="m">533.87613</span><span class="p">,</span><span class="m">414.58713</span><span class="p">,</span><span class="m">451.8851</span><span class="p">,</span><span class="m">409.28728</span><span class="p">,</span><span class="m">462.80969</span><span class="p">,</span><span class="m">363.90947</span><span class="p">,</span><span class="m">468.83368</span><span class="p">),</span>
<span class="w">  </span><span class="n">read</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">358.8281</span><span class="p">,</span><span class="m">419.71994</span><span class="p">,</span><span class="m">412.83373</span><span class="p">,</span><span class="m">498.79545</span><span class="p">,</span><span class="m">484.0255</span><span class="p">,</span><span class="m">481.7429</span><span class="p">,</span><span class="m">405.41276</span><span class="p">,</span><span class="m">413.32812</span><span class="p">,</span><span class="m">427.66587</span><span class="p">,</span><span class="m">490.52696</span><span class="p">,</span><span class="m">481.54308</span><span class="p">,</span><span class="m">465.12644</span><span class="p">,</span><span class="m">419.17929</span><span class="p">,</span><span class="m">415.22553</span><span class="p">,</span><span class="m">500.25072</span><span class="p">,</span><span class="m">483.0404</span><span class="p">,</span><span class="m">477.21655</span><span class="p">,</span><span class="m">353.15524</span><span class="p">,</span><span class="m">480.86845</span><span class="p">,</span><span class="m">513.84343</span><span class="p">,</span><span class="m">477.53438</span><span class="p">,</span><span class="m">467.01198</span><span class="p">,</span><span class="m">490.44853</span><span class="p">,</span><span class="m">375.03115</span><span class="p">,</span><span class="m">442.52392</span><span class="p">,</span><span class="m">375.55029</span><span class="p">,</span><span class="m">504.42272</span><span class="p">,</span><span class="m">475.74213</span><span class="p">,</span><span class="m">479.98543</span><span class="p">,</span><span class="m">372.90122</span><span class="p">,</span><span class="m">516.88935</span><span class="p">,</span><span class="m">436.02972</span><span class="p">,</span><span class="m">473.09826</span><span class="p">,</span><span class="m">480.65205</span><span class="p">,</span><span class="m">400.32092</span><span class="p">,</span><span class="m">341.46512</span><span class="p">,</span><span class="m">515.07793</span><span class="p">,</span><span class="m">404.15901</span><span class="p">,</span><span class="m">321.2015</span><span class="p">,</span><span class="m">517.97604</span><span class="p">,</span><span class="m">338.17407</span><span class="p">,</span><span class="m">466.72213</span><span class="p">,</span><span class="m">474.2778</span><span class="p">,</span><span class="m">510.36214</span><span class="p">,</span><span class="m">337.91559</span><span class="p">,</span><span class="m">412.49955</span><span class="p">,</span><span class="m">415.23693</span><span class="p">,</span><span class="m">360.23238</span><span class="p">,</span><span class="m">448.79677</span><span class="p">,</span><span class="m">405.80333</span><span class="p">,</span><span class="m">377.88235</span><span class="p">,</span><span class="m">389.52229</span><span class="p">,</span><span class="m">456.80425</span><span class="p">,</span><span class="m">476.63287</span><span class="p">,</span><span class="m">500.62093</span><span class="p">,</span><span class="m">387.40349</span><span class="p">,</span><span class="m">411.3118</span><span class="p">,</span><span class="m">345.80676</span><span class="p">,</span><span class="m">495.10716</span><span class="p">,</span><span class="m">480.06531</span><span class="p">,</span><span class="m">376.70185</span><span class="p">,</span><span class="m">348.16283</span><span class="p">,</span><span class="m">414.6251</span><span class="p">,</span><span class="m">366.71778</span><span class="p">,</span><span class="m">431.63915</span><span class="p">,</span><span class="m">436.35943</span><span class="p">,</span><span class="m">383.16603</span><span class="p">,</span><span class="m">542.47853</span><span class="p">,</span><span class="m">367.1504</span><span class="p">,</span><span class="m">440.34278</span><span class="p">,</span><span class="m">450.99055</span><span class="p">,</span><span class="m">455.30676</span><span class="p">,</span><span class="m">487.52261</span><span class="p">,</span><span class="m">504.32483</span><span class="p">,</span><span class="m">396.81118</span><span class="p">,</span><span class="m">454.84742</span><span class="p">,</span><span class="m">430.33206</span><span class="p">,</span><span class="m">501.33838</span><span class="p">,</span><span class="m">335.69292</span><span class="p">,</span><span class="m">461.27979</span><span class="p">),</span>
<span class="w">  </span><span class="n">scie</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">376.45612</span><span class="p">,</span><span class="m">434.89017</span><span class="p">,</span><span class="m">416.65516</span><span class="p">,</span><span class="m">507.91081</span><span class="p">,</span><span class="m">494.86606</span><span class="p">,</span><span class="m">494.80982</span><span class="p">,</span><span class="m">421.72777</span><span class="p">,</span><span class="m">405.9808</span><span class="p">,</span><span class="m">444.34865</span><span class="p">,</span><span class="m">500.98817</span><span class="p">,</span><span class="m">500.80958</span><span class="p">,</span><span class="m">461.86337</span><span class="p">,</span><span class="m">420.46238</span><span class="p">,</span><span class="m">410.20256</span><span class="p">,</span><span class="m">510.04275</span><span class="p">,</span><span class="m">495.53081</span><span class="p">,</span><span class="m">481.59372</span><span class="p">,</span><span class="m">361.725</span><span class="p">,</span><span class="m">491.143</span><span class="p">,</span><span class="m">528.51191</span><span class="p">,</span><span class="m">498.51606</span><span class="p">,</span><span class="m">481.40229</span><span class="p">,</span><span class="m">492.73984</span><span class="p">,</span><span class="m">385.03211</span><span class="p">,</span><span class="m">445.14657</span><span class="p">,</span><span class="m">374.28158</span><span class="p">,</span><span class="m">524.42376</span><span class="p">,</span><span class="m">482.90977</span><span class="p">,</span><span class="m">492.44187</span><span class="p">,</span><span class="m">395.31191</span><span class="p">,</span><span class="m">504.3107</span><span class="p">,</span><span class="m">447.24463</span><span class="p">,</span><span class="m">464.2001</span><span class="p">,</span><span class="m">480.90591</span><span class="p">,</span><span class="m">394.72014</span><span class="p">,</span><span class="m">373.75317</span><span class="p">,</span><span class="m">546.25504</span><span class="p">,</span><span class="m">440.96584</span><span class="p">,</span><span class="m">341.14726</span><span class="p">,</span><span class="m">531.3388</span><span class="p">,</span><span class="m">353.75366</span><span class="p">,</span><span class="m">479.50271</span><span class="p">,</span><span class="m">493.00024</span><span class="p">,</span><span class="m">543.14931</span><span class="p">,</span><span class="m">364.28557</span><span class="p">,</span><span class="m">418.00956</span><span class="p">,</span><span class="m">410.76032</span><span class="p">,</span><span class="m">381.67947</span><span class="p">,</span><span class="m">468.78635</span><span class="p">,</span><span class="m">404.08089</span><span class="p">,</span><span class="m">411.62124</span><span class="p">,</span><span class="m">417.15835</span><span class="p">,</span><span class="m">486.63188</span><span class="p">,</span><span class="m">478.18198</span><span class="p">,</span><span class="m">503.74646</span><span class="p">,</span><span class="m">383.48177</span><span class="p">,</span><span class="m">410.52702</span><span class="p">,</span><span class="m">355.28466</span><span class="p">,</span><span class="m">504.86972</span><span class="p">,</span><span class="m">487.69184</span><span class="p">,</span><span class="m">371.42047</span><span class="p">,</span><span class="m">367.63747</span><span class="p">,</span><span class="m">428.26692</span><span class="p">,</span><span class="m">381.6494</span><span class="p">,</span><span class="m">453.79679</span><span class="p">,</span><span class="m">436.78672</span><span class="p">,</span><span class="m">390.96302</span><span class="p">,</span><span class="m">560.97909</span><span class="p">,</span><span class="m">374.21203</span><span class="p">,</span><span class="m">447.30452</span><span class="p">,</span><span class="m">467.28861</span><span class="p">,</span><span class="m">486.88349</span><span class="p">,</span><span class="m">494.4219</span><span class="p">,</span><span class="m">526.40753</span><span class="p">,</span><span class="m">429.0165</span><span class="p">,</span><span class="m">475.16645</span><span class="p">,</span><span class="m">435.88107</span><span class="p">,</span><span class="m">497.41058</span><span class="p">,</span><span class="m">355.05556</span><span class="p">,</span><span class="m">472.23249</span><span class="p">),</span>
<span class="w">  </span><span class="n">econ_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">-.74391004</span><span class="p">,</span><span class="n">.</span><span class="m">32525118</span><span class="p">,</span><span class="m">-.67148081</span><span class="p">,</span><span class="n">.</span><span class="m">39335586</span><span class="p">,</span><span class="n">.</span><span class="m">09302247</span><span class="p">,</span><span class="n">.</span><span class="m">1154232</span><span class="p">,</span><span class="m">-.27047491</span><span class="p">,</span><span class="m">-.97523877</span><span class="p">,</span><span class="m">-.27116078</span><span class="p">,</span><span class="n">.</span><span class="m">3339245</span><span class="p">,</span><span class="n">.</span><span class="m">1809795</span><span class="p">,</span><span class="m">-.24284266</span><span class="p">,</span><span class="m">-.96515588</span><span class="p">,</span><span class="kc">NA</span><span class="p">,</span><span class="m">-.01307006</span><span class="p">,</span><span class="m">-.12423293</span><span class="p">,</span><span class="n">.</span><span class="m">34054443</span><span class="p">,</span><span class="m">-.71082132</span><span class="p">,</span><span class="n">.</span><span class="m">02354851</span><span class="p">,</span><span class="n">.</span><span class="m">18467558</span><span class="p">,</span><span class="n">.</span><span class="m">19358048</span><span class="p">,</span><span class="m">-.05861012</span><span class="p">,</span><span class="n">.</span><span class="m">11972009</span><span class="p">,</span><span class="m">-.44695238</span><span class="p">,</span><span class="m">-.13303286</span><span class="p">,</span><span class="m">-1.4975343</span><span class="p">,</span><span class="m">-.45290783</span><span class="p">,</span><span class="m">-.1523256</span><span class="p">,</span><span class="n">.</span><span class="m">06026681</span><span class="p">,</span><span class="m">-1.4481847</span><span class="p">,</span><span class="n">.</span><span class="m">34413547</span><span class="p">,</span><span class="n">.</span><span class="m">38376268</span><span class="p">,</span><span class="n">.</span><span class="m">25381603</span><span class="p">,</span><span class="m">-.09725531</span><span class="p">,</span><span class="m">-.57839371</span><span class="p">,</span><span class="m">-.80391485</span><span class="p">,</span><span class="m">-.02354713</span><span class="p">,</span><span class="m">-.26977891</span><span class="p">,</span><span class="m">-2.0669077</span><span class="p">,</span><span class="n">.</span><span class="m">23721704</span><span class="p">,</span><span class="m">-.3564011</span><span class="p">,</span><span class="n">.</span><span class="m">03484754</span><span class="p">,</span><span class="m">-.00981672</span><span class="p">,</span><span class="m">-.44904569</span><span class="p">,</span><span class="m">-1.8117468</span><span class="p">,</span><span class="m">-.50431186</span><span class="p">,</span><span class="m">-.92555928</span><span class="p">,</span><span class="m">-.26902116</span><span class="p">,</span><span class="n">.</span><span class="m">04917327</span><span class="p">,</span><span class="m">-.1922437</span><span class="p">,</span><span class="m">-.73720841</span><span class="p">,</span><span class="m">-.66233746</span><span class="p">,</span><span class="n">.</span><span class="m">23876144</span><span class="p">,</span><span class="n">.</span><span class="m">52544167</span><span class="p">,</span><span class="n">.</span><span class="m">22389294</span><span class="p">,</span><span class="m">-.96079427</span><span class="p">,</span><span class="m">-1.1207972</span><span class="p">,</span><span class="m">-1.3333803</span><span class="p">,</span><span class="m">-.06879525</span><span class="p">,</span><span class="m">-.2048969</span><span class="p">,</span><span class="m">-1.2130009</span><span class="p">,</span><span class="m">-.91617362</span><span class="p">,</span><span class="n">.</span><span class="m">11453604</span><span class="p">,</span><span class="m">-.46005621</span><span class="p">,</span><span class="m">-.29700884</span><span class="p">,</span><span class="m">-.28406969</span><span class="p">,</span><span class="m">-.27803347</span><span class="p">,</span><span class="n">.</span><span class="m">29037254</span><span class="p">,</span><span class="m">-1.3106626</span><span class="p">,</span><span class="m">-.20093189</span><span class="p">,</span><span class="m">-.25804407</span><span class="p">,</span><span class="n">.</span><span class="m">15198116</span><span class="p">,</span><span class="n">.</span><span class="m">33239471</span><span class="p">,</span><span class="m">-.28002015</span><span class="p">,</span><span class="m">-.96258429</span><span class="p">,</span><span class="m">-1.2274957</span><span class="p">,</span><span class="m">-.81679644</span><span class="p">,</span><span class="n">.</span><span class="m">04198107</span><span class="p">,</span><span class="m">-.68010732</span><span class="p">,</span><span class="m">-1.3159208</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">datos</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">na.omit</span><span class="p">(</span><span class="n">datos</span><span class="p">)</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">datos</span><span class="o">$</span><span class="n">econ_index</span><span class="p">,</span><span class="w"> </span><span class="n">datos</span><span class="o">$</span><span class="n">read</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Economic Index&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Reading Test Scores - PISA 2022&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/7ae7e9726d9f2bdceaf9dacefbfc1373fb9d7b838e5ab9b3e550a95fd41306f0.png"><img alt="_images/7ae7e9726d9f2bdceaf9dacefbfc1373fb9d7b838e5ab9b3e550a95fd41306f0.png" src="_images/7ae7e9726d9f2bdceaf9dacefbfc1373fb9d7b838e5ab9b3e550a95fd41306f0.png" style="width: 420px; height: 420px;" />
</a>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">read</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">econ_index</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">datos</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Call:
lm(formula = read ~ econ_index, data = datos)

Residuals:
    Min      1Q  Median      3Q     Max 
-98.150 -20.616   3.319  24.557  91.063 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  460.878      5.218  88.331  &lt; 2e-16 ***
econ_index    68.896      7.821   8.809  2.8e-13 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 39.54 on 77 degrees of freedom
Multiple R-squared:  0.5019,	Adjusted R-squared:  0.4955 
F-statistic:  77.6 on 1 and 77 DF,  p-value: 2.797e-13
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#Prediccion</span>
<span class="n">model_fit</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">as.data.frame</span><span class="p">(</span><span class="nf">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">se.fit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="n">interval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;confidence&quot;</span><span class="p">,</span><span class="w">  </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">datos</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.99</span><span class="p">))</span>
<span class="nf">names</span><span class="p">(</span><span class="n">model_fit</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&#39;yhat&#39;</span><span class="p">,</span><span class="w"> </span><span class="s">&#39;lwr&#39;</span><span class="p">,</span><span class="w"> </span><span class="s">&#39;upr&#39;</span><span class="p">,</span><span class="w"> </span><span class="s">&#39;se&#39;</span><span class="p">,</span><span class="w"> </span><span class="s">&#39;df&#39;</span><span class="p">,</span><span class="w"> </span><span class="s">&#39;residuals&#39;</span><span class="p">)</span>
<span class="nf">head</span><span class="p">(</span><span class="n">model_fit</span><span class="p">,</span><span class="w"> </span><span class="m">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A data.frame: 5 × 6</caption>
<thead>
	<tr><th></th><th scope=col>yhat</th><th scope=col>lwr</th><th scope=col>upr</th><th scope=col>se</th><th scope=col>df</th><th scope=col>residuals</th></tr>
	<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><th scope=row>1</th><td>409.6258</td><td>395.3168</td><td>423.9347</td><td>5.417594</td><td>77</td><td>39.54123</td></tr>
	<tr><th scope=row>2</th><td>483.2867</td><td>465.0712</td><td>501.5022</td><td>6.896686</td><td>77</td><td>39.54123</td></tr>
	<tr><th scope=row>3</th><td>414.6158</td><td>401.1048</td><td>428.1269</td><td>5.115512</td><td>77</td><td>39.54123</td></tr>
	<tr><th scope=row>4</th><td>487.9789</td><td>468.6670</td><td>507.2907</td><td>7.311772</td><td>77</td><td>39.54123</td></tr>
	<tr><th scope=row>5</th><td>467.2871</td><td>452.4118</td><td>482.1624</td><td>5.632037</td><td>77</td><td>39.54123</td></tr>
</tbody>
</table>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">plot</span><span class="p">(</span><span class="n">datos</span><span class="o">$</span><span class="n">econ_index</span><span class="p">,</span><span class="w"> </span><span class="n">datos</span><span class="o">$</span><span class="n">read</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Economic Index&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Reading Test Scores - PISA 2022&quot;</span><span class="p">)</span>
<span class="nf">lines</span><span class="p">(</span><span class="n">datos</span><span class="o">$</span><span class="n">econ_index</span><span class="p">,</span><span class="w"> </span><span class="n">model_fit</span><span class="o">$</span><span class="n">yhat</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;blue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">lty</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/5cccca952268248c763c1489dd74e5c47a0c6fed27ce311138f773101becb1b2.png"><img alt="_images/5cccca952268248c763c1489dd74e5c47a0c6fed27ce311138f773101becb1b2.png" src="_images/5cccca952268248c763c1489dd74e5c47a0c6fed27ce311138f773101becb1b2.png" style="width: 420px; height: 420px;" />
</a>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#Predecir los errores</span>
<span class="n">e</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">datos</span><span class="o">$</span><span class="n">read</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">model_fit</span><span class="o">$</span><span class="n">yhat</span>

<span class="c1">#Estimacion de la función de densidad</span>
<span class="nf">hist</span><span class="p">(</span><span class="n">e</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">T</span><span class="p">)</span>
<span class="nf">lines</span><span class="p">(</span><span class="nf">density</span><span class="p">(</span><span class="n">e</span><span class="p">),</span><span class="w"> </span><span class="n">lty</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">lw</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/45e5aa4d613b994598e16c7c5d3e407b91d3a9d7bf92456c319951765124cefc.png"><img alt="_images/45e5aa4d613b994598e16c7c5d3e407b91d3a9d7bf92456c319951765124cefc.png" src="_images/45e5aa4d613b994598e16c7c5d3e407b91d3a9d7bf92456c319951765124cefc.png" style="width: 420px; height: 420px;" />
</a>
</div>
</div>
</section>
<section id="residuales-de-la-regresion-e-i-y-i-hat-y-i">
<h2>Residuales de la Regresión: <span class="math notranslate nohighlight">\(e_i = Y_i - \hat Y_i\)</span><a class="headerlink" href="#residuales-de-la-regresion-e-i-y-i-hat-y-i" title="Link to this heading">#</a></h2>
<p>Observe que a partir de las ecuaciones normales tenemos que</p>
<div class="math notranslate nohighlight">
\[\sum_i ({Y_i} - \hat\beta_0 - \hat\beta_1 X_i) = \sum_i e_i = 0\]</div>
<div class="math notranslate nohighlight">
\[\sum_i (X_i) \cdot ({Y_i} - \hat\beta_0 - \hat\beta_1 X_i) = \sum_i e_i \cdot X_i = 0\]</div>
<p>Lo anterior indica que:</p>
<div class="math notranslate nohighlight">
\[\frac{\sum_i e_i}{n} = \bar e = 0 \hspace{5pt} \Rightarrow \hspace{5pt} \bar Y = \bar{\hat Y}\]</div>
<div class="math notranslate nohighlight">
\[\sum_i e_i \cdot X_i = 0 \hspace{5pt} \Rightarrow \hspace{5pt} \mathbb{\hat Cov}(e_i, X_i) = \sum_i (e_i - \bar e) \cdot (X_i - \bar X) = 0\]</div>
</section>
<section id="propiedades-de-los-estimadores-hat-beta-k">
<h2>Propiedades de los estimadores <span class="math notranslate nohighlight">\(\hat\beta_k\)</span><a class="headerlink" href="#propiedades-de-los-estimadores-hat-beta-k" title="Link to this heading">#</a></h2>
<p>Queremos evaluar si <span class="math notranslate nohighlight">\(\hat\beta_1\)</span> es un buen estimador de <span class="math notranslate nohighlight">\(\beta_1\)</span>.</p>
<p>La primera pregunta que nos hacemos es ¿<span class="math notranslate nohighlight">\(E(\hat\beta_1) = \beta_1\)</span>? Es decir, queremos ver si <span class="math notranslate nohighlight">\(\hat\beta_1\)</span> es un estimador insesgado.</p>
<p>Note que</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \hat\beta_1 &amp; = \frac{\sum_i (X_i - \overline X)(Y_i - \overline Y)}{\sum_i (X_i - \overline X)^2}\\
     &amp; = \frac{\sum_i (X_i - \overline X)(\beta_0 + \beta_1 X_i + \varepsilon_i - \beta_0 - \beta_1 \bar X - \bar \varepsilon)}{\sum_i (X_i - \overline X)^2}\\
    &amp; = \beta_1 + \frac{\sum_i (X_i - \overline X)(\varepsilon_i - \overline \varepsilon)}{\sum_i (X_i - \overline X)^2}\\
    &amp; = \beta_1 + \frac{\sum_i (X_i - \overline X) \cdot \varepsilon_i}{\sum_i (X_i - \overline X)^2} \\     
\end{align*}\]</div>
<p>Si tomamos la esperanza de esta exprensión tenemos:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    E(\hat\beta_1) &amp; = \beta_1 + E \left(\frac{\sum_i (X_i - \overline X) \cdot \varepsilon_i}{\sum_i (X_i - \overline X)^2}\right) \\    
\end{align*}\]</div>
<p>A partir del supuesto de <strong>independencia condicional</strong>, para todo <span class="math notranslate nohighlight">\(i\)</span> y <span class="math notranslate nohighlight">\(j\)</span>, <span class="math notranslate nohighlight">\(\varepsilon_i\)</span> y <span class="math notranslate nohighlight">\(X_j\)</span> son independientes. Es decir,</p>
<div class="math notranslate nohighlight">
\[E(\varepsilon_i \cdot X_j) = E(\varepsilon_i) \cdot E(X_j) = 0\]</div>
<p>Debido a esto:</p>
<div class="math notranslate nohighlight">
\[E\left(\sum_i (X_i - \overline X) \cdot \varepsilon_i\right) = \sum_i E(X_i \varepsilon_i) - \sum_i E(\overline X \varepsilon_i) = \sum_i E(X_i) E(\varepsilon_i) - \sum_i E(\overline X) E(\varepsilon_i) = 0\]</div>
<p>De esta manera, el estimador <span class="math notranslate nohighlight">\(\hat\beta_1\)</span>, que obtuvimos por el método MCO, es insesgado. Así,</p>
<div class="math notranslate nohighlight">
\[E(\hat\beta_1) = \beta_1\]</div>
<p>Es <span class="math notranslate nohighlight">\(\beta_0\)</span> un estimador insesgado?</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    E(\hat\beta_0) &amp; =E \left(\overline Y - \hat\beta_1 \overline X \right)\\
     &amp; = E\left(\beta_0 + \beta_1 \overline X + \overline\varepsilon - \hat\beta_1 \overline X\right)\\
     &amp; = \beta_0 + \beta_1 E(\overline X) + E(\overline\varepsilon) - \beta_1 E(\overline X)\\
     &amp; = \beta_0 \\
\end{align*}\]</div>
</section>
<section id="inferencia-en-regresion-simple">
<h2>Inferencia en Regresión Simple<a class="headerlink" href="#inferencia-en-regresion-simple" title="Link to this heading">#</a></h2>
<p>Luego de estimar el modelo, y saber que en promedio nuestros estimadores de MCO encuentran los verdaderos parámetros que se desconocen, queremos determinar si</p>
<ol class="arabic simple">
<li><p>existe una relación <strong>estádisticamente significativa</strong> entre <span class="math notranslate nohighlight">\(Y\)</span> y <span class="math notranslate nohighlight">\(X\)</span></p></li>
<li><p>nuestro modelo tiene un buen ajuste (o poder predictivo)</p></li>
</ol>
<p>Con este objetivo en mente,</p>
<ol class="arabic simple">
<li><p>realizaremos pruebas de hipotesis individuales y conjuntas</p></li>
<li><p>computaremos el coeficiente de determinación <span class="math notranslate nohighlight">\(R^2\)</span>.</p></li>
</ol>
</section>
<section id="pruebas-de-hipotesis-sobre-hat-beta-k">
<h2>Pruebas de Hipótesis sobre <span class="math notranslate nohighlight">\(\hat\beta_k\)</span><a class="headerlink" href="#pruebas-de-hipotesis-sobre-hat-beta-k" title="Link to this heading">#</a></h2>
<p>Debido al supuesto de <strong>normalidad de los errores</strong>, <span class="math notranslate nohighlight">\(\varepsilon_i | X \sim N(0, \sigma^2)\)</span>, es posible probar que</p>
<div class="math notranslate nohighlight">
\[\hat\beta_k | X \sim N(\beta_k, \sigma^2_\beta)\]</div>
<p>Sin entrar en detalles, recuerde que la suma de variables normales da como resultado una variable que se distribuye normal. Esta es la idea fundamental detrás de la demostración de que nuestros estimadores de MCO son normales.</p>
<p>La hipotesis que queremos considerar en general toma la siguiente forma:</p>
<div class="math notranslate nohighlight">
\[H_0 : \beta_k = 0\]</div>
<div class="math notranslate nohighlight">
\[H_1 : \beta_k \neq 0\]</div>
<p>Note que bajo la hipótesis nula (<span class="math notranslate nohighlight">\(H_0\)</span>) el parámetro <span class="math notranslate nohighlight">\(\beta_k\)</span> es cero, y queremos saber si podemos rechazar dicha hipotesis con un nivel de significancia <span class="math notranslate nohighlight">\(\alpha \in \{0.1, 0.05, 0.01\}\)</span>.</p>
<p>Para probar esta hipótesis podemoslos usar el siguiente estadístico:</p>
<div class="math notranslate nohighlight">
\[\frac{\hat\beta_k - \beta_k}{\sigma_\beta}\]</div>
<p>Sin embargo, desconocemos <span class="math notranslate nohighlight">\(\sigma_\beta\)</span>. Esto implica que debemos estimarlo.</p>
</section>
<section id="varianza-de-hat-beta-k">
<h2>Varianza de <span class="math notranslate nohighlight">\(\hat\beta_k\)</span><a class="headerlink" href="#varianza-de-hat-beta-k" title="Link to this heading">#</a></h2>
<p>Recuerde <span class="math notranslate nohighlight">\(\hat\beta_1 = \frac{\mathbb{\hat Cov}(X, Y)}{\mathbb{\hat V}(X)} = \beta_1 + \frac{\sum_i (X_i - \overline X) \cdot \varepsilon_i}{\sum_i (X_i - \overline X)^2}\)</span>. De esta manera,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    V(\hat\beta_1 | X) &amp; = E \left(\hat\beta_1 - E(\hat\beta_1) | X \right)^2 = E \left(\hat\beta_1 - \beta_1 | X \right)^2 = E \left(\frac{\sum_i (X_i - \overline X) \cdot \varepsilon_i}{\sum_i (X_i - \overline X)^2} | X \right)^2 \\ 
    &amp; = \left(\frac{1}{\sum_i (X_i - \overline X)^2}\right)^2 E \left(\sum_i (X_i - \overline X) \cdot \varepsilon_i | X \right)^2 \\
    &amp; = \left(\frac{1}{\sum_i (X_i - \overline X)^2}\right)^2 E \left(\sum_i (X_i - \overline X)^2 \cdot \varepsilon_i^2 + 2 \sum_{i &lt; j} (X_i - \overline X) (X_j - \overline X) \varepsilon_i \varepsilon_j | X \right) \\
    &amp; = \left(\frac{1}{\sum_i (X_i - \overline X)^2}\right)^2 \left(\sum_i (X_i - \overline X)^2 \cdot E(\varepsilon_i^2 | X) \right) \\ 
    &amp; = \frac{\sigma^2}{\sum_i (X_i - \overline X)^2} = \frac{\sigma^2}{S^2_X (n-1)} \\
\end{align*}\]</div>
<p>Note que para estimar esta varianza debemos encontrar un estimador para <span class="math notranslate nohighlight">\(\sigma^2\)</span></p>
</section>
<section id="varianza-de-los-errores">
<h2>Varianza de los Errores<a class="headerlink" href="#varianza-de-los-errores" title="Link to this heading">#</a></h2>
<p>Antes de encontrar un estimador para <span class="math notranslate nohighlight">\(\sigma^2\)</span>, note que</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    V(Y_i | X_i) &amp; = V(\beta_0 + \beta_1 X_i + \varepsilon_i | X) \\
    &amp; = V(\beta_0 + \beta_1 X_i | X) + V(\varepsilon_i | X) + 2 \cdot Cov(\beta_0 + \beta_1 X_i, \varepsilon_i | X) \\
    &amp; = V(\varepsilon_i | X) = \sigma^2 \\
\end{align*}\]</div>
<p>Más aún, observe que</p>
<div class="math notranslate nohighlight">
\[Y_i | X \sim N(\beta_0 + \beta_1 X_i, \sigma^2)\]</div>
<p>Ahora, ya que <span class="math notranslate nohighlight">\(E(\varepsilon_i) = 0\)</span>, podemos mostrar que</p>
<div class="math notranslate nohighlight">
\[V(\varepsilon_i | X) = E(\varepsilon_i^2)\]</div>
<p>Un estimador para <span class="math notranslate nohighlight">\(\sigma^2\)</span> es:</p>
<div class="math notranslate nohighlight">
\[\hat\sigma^2 = \frac{\sum_i e_i^2}{n-K} = \frac{\sum_i (Y_i - \hat Y_i)^2}{n-K} = \frac{\sum_i (Y_i - \hat\beta_0 - \hat\beta_1 X_i)^2}{n-K} \]</div>
<p>Donde <span class="math notranslate nohighlight">\(K\)</span> es el número de parámetros que debemos estimar. En este caso <span class="math notranslate nohighlight">\(K = 2\)</span>.</p>
</section>
<section id="pruebas-de-hipotesis-individuales">
<h2>Pruebas de Hipótesis Individuales<a class="headerlink" href="#pruebas-de-hipotesis-individuales" title="Link to this heading">#</a></h2>
<p>Para nuestra prueba de hipótesis</p>
<div class="math notranslate nohighlight">
\[H_0 : \beta_1 = 0\]</div>
<div class="math notranslate nohighlight">
\[H_1 : \beta_1 \neq 0\]</div>
<p>Usaremos el siguiente estadístico de prueba</p>
<div class="math notranslate nohighlight">
\[T = \frac{\hat\beta_1 - \beta_1}{\text{ee}(\hat\beta_1)}\]</div>
<p>Donde el error estandar de <span class="math notranslate nohighlight">\(\hat\beta_1\)</span> se define como:</p>
<div class="math notranslate nohighlight">
\[\text{ee}(\hat\beta_1) = \sqrt{ \frac{\sum_i e_i^2/n-K}{\sum_i (X_i - \overline X)^2}}\]</div>
<p>Observe que nuestro estadístico <span class="math notranslate nohighlight">\(T \sim t_{n-K}\)</span>. Esto se debe a que <span class="math notranslate nohighlight">\(\hat\beta_1 \sim N(\beta_1, \sigma_{\beta_1})\)</span> y <span class="math notranslate nohighlight">\(\sum_i e_i^2 \sim \chi^2_{n-K}\)</span></p>
</section>
<section id="intervalo-de-confianza-para-beta-k">
<h2>Intervalo de confianza para <span class="math notranslate nohighlight">\(\beta_k\)</span><a class="headerlink" href="#intervalo-de-confianza-para-beta-k" title="Link to this heading">#</a></h2>
<p>Nuestro intervalo de confianza para el parámetro desconocido <span class="math notranslate nohighlight">\(\beta_k\)</span> está dado por</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    IC &amp; = \left(\beta_k - t_{\alpha/2 \hspace{2pt},\hspace{2pt} n-K}\cdot\sqrt{ \frac{\sum_i e_i^2/n-K}{\sum_i (X_i - \overline X)^2}} \hspace{5pt} , \hspace{5pt} \beta_k + t_{\alpha/2 \hspace{2pt},\hspace{2pt} n - K}\cdot\sqrt{ \frac{\sum_i e_i^2/n-K}{\sum_i (X_i - \overline X)^2}} \right)
\end{align*}\]</div>
<p>Cuando <span class="math notranslate nohighlight">\(n\)</span> es grande, si <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>, entonces <span class="math notranslate nohighlight">\(|t_{\alpha/2 \hspace{2pt},\hspace{2pt} n-K}| \approx 1.96\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">8</span><span class="p">,</span><span class="w"> </span><span class="m">9</span><span class="p">,</span><span class="w"> </span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">7</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">)</span><span class="w"> </span><span class="c1">#Precio</span>
<span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="m">11</span><span class="p">,</span><span class="w"> </span><span class="m">6</span><span class="p">,</span><span class="w"> </span><span class="m">9</span><span class="p">)</span><span class="w"> </span><span class="c1">#Cantidades</span>
<span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1">#b0 y b1</span>
<span class="n">b1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">cov</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="nf">var</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">b0</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">b1</span><span class="o">*</span><span class="nf">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">paste0</span><span class="p">(</span><span class="s">&#39;Beta 0 = &#39;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">b0</span><span class="p">,</span><span class="w"> </span><span class="m">5</span><span class="p">),</span><span class="w"> </span><span class="s">&#39; Beta 1 = &#39;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">b1</span><span class="p">,</span><span class="w"> </span><span class="m">5</span><span class="p">)))</span>

<span class="c1">#Errores estandar de b1</span>
<span class="nf">print</span><span class="p">(</span><span class="s">&#39;Yhat :&#39;</span><span class="p">)</span>
<span class="n">yhat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">(</span><span class="n">b0</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">b1</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">x</span><span class="p">);</span><span class="w"> </span><span class="n">yhat</span>
<span class="nf">print</span><span class="p">(</span><span class="s">&#39;Residuales :&#39;</span><span class="p">)</span>
<span class="n">e</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">yhat</span><span class="p">;</span><span class="w"> </span><span class="n">e</span>
<span class="n">var_b1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">e</span><span class="o">^</span><span class="m">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">n</span><span class="m">-2</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="nf">var</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">n</span><span class="m">-1</span><span class="p">))</span>
<span class="n">ee_b1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var_b1</span><span class="p">);</span><span class="w"> </span><span class="nf">print</span><span class="p">(</span><span class="nf">paste0</span><span class="p">(</span><span class="s">&#39;Error Estandar B1 = &#39;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">ee_b1</span><span class="p">,</span><span class="w"> </span><span class="m">5</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] &quot;Beta 0 = 11.57751 Beta 1 = -0.84802&quot;
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] &quot;Yhat :&quot;
</pre></div>
</div>
<div class="output text_html"><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>8.1854103343465</li><li>9.03343465045593</li><li>3.09726443768997</li><li>2.24924012158055</li><li>6.48936170212766</li><li>3.94528875379939</li></ol>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] &quot;Residuales :&quot;
</pre></div>
</div>
<div class="output text_html"><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>-0.185410334346503</li><li>-0.0334346504559271</li><li>0.902735562310031</li><li>-0.249240121580547</li><li>0.51063829787234</li><li>-0.945288753799391</li></ol>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] &quot;Error Estandar B1 = 0.09707&quot;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#Estadistico T</span>
<span class="nf">print</span><span class="p">(</span><span class="s">&#39;Estadistico T = &#39;</span><span class="p">)</span>
<span class="bp">T</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">b1</span><span class="o">/</span><span class="n">ee_b1</span><span class="p">;</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="bp">T</span><span class="p">,</span><span class="w"> </span><span class="m">5</span><span class="p">)</span>

<span class="c1">#Intervalo de Confianza</span>
<span class="n">alpha</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.05</span>
<span class="n">low</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">b1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">abs</span><span class="p">(</span><span class="nf">qt</span><span class="p">(</span><span class="n">alpha</span><span class="o">/</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="m">-2</span><span class="p">))</span><span class="o">*</span><span class="n">ee_b1</span>
<span class="n">up</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">b1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">abs</span><span class="p">(</span><span class="nf">qt</span><span class="p">(</span><span class="n">alpha</span><span class="o">/</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="m">-2</span><span class="p">))</span><span class="o">*</span><span class="n">ee_b1</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">paste0</span><span class="p">(</span><span class="s">&#39;IC = (&#39;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">low</span><span class="p">,</span><span class="w"> </span><span class="m">5</span><span class="p">)</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="s">&#39; , &#39;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">up</span><span class="p">,</span><span class="w"> </span><span class="m">5</span><span class="p">),</span><span class="w"> </span><span class="s">&#39;)&#39;</span><span class="p">))</span>

<span class="c1">#P-valor</span>
<span class="nf">print</span><span class="p">(</span><span class="s">&#39;P-valor =&#39;</span><span class="p">)</span>
<span class="nf">round</span><span class="p">((</span><span class="m">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">pt</span><span class="p">(</span><span class="nf">abs</span><span class="p">(</span><span class="bp">T</span><span class="p">),</span><span class="w"> </span><span class="n">n</span><span class="m">-2</span><span class="p">))</span><span class="o">*</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">6</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estadistico T = &quot;
</pre></div>
</div>
<div class="output text_html">-8.73583</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] &quot;IC = (-1.11755 , -0.5785)&quot;
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] &quot;P-valor =&quot;
</pre></div>
</div>
<div class="output text_html">0.000946</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">summary</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Call:
lm(formula = y ~ x)

Residuals:
       1        2        3        4        5        6 
-0.18541 -0.03343  0.90274 -0.24924  0.51064 -0.94529 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 11.57751    0.75506  15.333 0.000106 ***
x           -0.84802    0.09707  -8.736 0.000946 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.7188 on 4 degrees of freedom
Multiple R-squared:  0.9502,	Adjusted R-squared:  0.9377 
F-statistic: 76.31 on 1 and 4 DF,  p-value: 0.0009461
</pre></div>
</div>
</div>
</div>
</section>
<section id="coeficiente-de-determinacion-r-2">
<h2>Coeficiente de Determinación: <span class="math notranslate nohighlight">\(R^2\)</span><a class="headerlink" href="#coeficiente-de-determinacion-r-2" title="Link to this heading">#</a></h2>
<p>Una segunda forma de evaluar nuestro modelo es sabiendo qué tanto de <span class="math notranslate nohighlight">\(\boldsymbol{Y}\)</span> puede <span class="math notranslate nohighlight">\(\boldsymbol{X}\)</span> explicar.</p>
<p>Para saber esto debemos hacer lo siguiente:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
Y_i  &amp;= \hat Y_i + e_i \\
Y_i -\bar{Y} &amp;= \hat Y_i -\bar{Y} + e_i \\
\sum_i (Y_i -\bar{Y})^2 &amp;= \sum_i (\hat Y_i -\bar{Y} + e_i)^2 \\
\sum_i (Y_i -\bar{Y})^2 &amp;= \sum_i (\hat Y_i -\bar{Y})^2 + \sum_i e_i^2 + 2 \sum_i e_i (\hat Y_i -\bar{Y}) \\
\sum_i (Y_i -\bar{Y})^2 &amp;= \sum_i (\hat Y_i -\bar{Y})^2 + \sum_i e_i^2
\end{align*}\]</div>
<p>Esto es así porque</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\sum_i e_i (\hat Y_i -\bar{Y}) &amp;= \sum_i e_i \hat Y_i - \bar{Y}\sum e_i \\
&amp;= \sum_i e_i(\hat \beta_0 + \hat \beta_1 X_i) - \bar{Y}\sum e_i = 0
\end{align*}\]</div>
<p>Es decir, a partir de nuestros estimadores de MCO</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\underbrace{\sum_i (Y_i -\bar{Y})^2}_{\text{Varianza Total } (SST)} &amp;= \sum_i (\hat Y_i -\bar{Y})^2 + \sum_i e_i^2 \\
&amp;= \underbrace{\sum_i (\hat Y_i -\bar{Y})^2}_{\text{Varianza Explicada } (SSR)} + \underbrace{\sum_i (Y_i - \hat Y_i)^2}_{\text{Varianza No Explicada } (SSE)}
\end{align*}\]</div>
<p>Luego podemos definir:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
R^2 &amp;= \frac{SSR}{SST} = 1 - \frac{SSE}{SST} \\
&amp;= \frac{\sum_i (\hat Y_i -\bar{Y})^2}{\sum_i (Y_i -\bar{Y})^2} = 1 - \frac{\sum_i (Y_i - \hat Y_i)^2}{\sum_i (Y_i -\bar{Y})^2}
\end{align*}\]</div>
<p>Observe que el coeficiente de determinación está acodato, es decir,</p>
<div class="math notranslate nohighlight">
\[0 \leq R^2 \leq 1\]</div>
<p>Este estadístico <strong>mide qué tanto de la varianza de <span class="math notranslate nohighlight">\(Y\)</span> es explicada por la covariable <span class="math notranslate nohighlight">\(X\)</span></strong></p>
<div class="alert alert-block alert-danger"> 
<b>Nota:</b>
<p>
<p>En el modelo de regresión lineal, el coeficiente de determinación crece a medida que se incluyen más variables explicativas o covariables.</p>
</div>
<p>Para el modelo de regresión simple podemos demostar que</p>
<div class="math notranslate nohighlight">
\[\rho_{Y,X}^2 = R^2\]</div>
<p>donde <span class="math notranslate nohighlight">\(\rho_{Y,X}\)</span> es el coeficiente de correlación entre <span class="math notranslate nohighlight">\(X\)</span> y <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#Coeficiente de Determinación, R2</span>
<span class="n">SST</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">((</span><span class="n">y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">y</span><span class="p">))</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>
<span class="n">SSR</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">((</span><span class="n">yhat</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">y</span><span class="p">))</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>
<span class="n">SSE</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">((</span><span class="n">y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">yhat</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>

<span class="n">R2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">SSR</span><span class="o">/</span><span class="n">SST</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">paste0</span><span class="p">(</span><span class="s">&#39;R-cuadrado = &#39;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">R2</span><span class="p">,</span><span class="w"> </span><span class="m">5</span><span class="p">)))</span>

<span class="c1">#Coficiente de Correlacion entre X y Y</span>
<span class="n">rho</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">cov</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="nf">sd</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="nf">sd</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">paste0</span><span class="p">(</span><span class="s">&#39;Coeficiente de Correlacion = &#39;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">rho</span><span class="o">^</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">5</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] &quot;R-cuadrado = 0.9502&quot;
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] &quot;Coeficiente de Correlacion = 0.9502&quot;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">summary</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Call:
lm(formula = y ~ x)

Residuals:
       1        2        3        4        5        6 
-0.18541 -0.03343  0.90274 -0.24924  0.51064 -0.94529 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 11.57751    0.75506  15.333 0.000106 ***
x           -0.84802    0.09707  -8.736 0.000946 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.7188 on 4 degrees of freedom
Multiple R-squared:  0.9502,	Adjusted R-squared:  0.9377 
F-statistic: 76.31 on 1 and 4 DF,  p-value: 0.0009461
</pre></div>
</div>
</div>
</div>
</section>
<section id="prueba-de-significancia-global">
<h2>Prueba de Significancia Global<a class="headerlink" href="#prueba-de-significancia-global" title="Link to this heading">#</a></h2>
<p>La idea de esta prueba es evaluar si todas las covariables que incluimos en el modelo pueden explicar conjuntamente la variable <span class="math notranslate nohighlight">\(Y\)</span></p>
<p>La prueba de signifiancia global se define como:</p>
<div class="math notranslate nohighlight">
\[H_0 : \beta_1 = \beta_2 = ... = \beta_K = 0\]</div>
<div class="math notranslate nohighlight">
\[H_1 : \text{ al menos un } \beta_k \text{ es diferente de 0}\]</div>
<p>Esta es una prueba de ‘cola derecha,’ por lo tanto la zona de rechazo siempre va a ser a la derecha e igual a <span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
<p>Observe que en el modelo de regresión univariada (o simple), esta prueba es equivalente a:</p>
<div class="math notranslate nohighlight">
\[H_0 : \beta_1 = 0\]</div>
<div class="math notranslate nohighlight">
\[H_1 : \beta_1 \neq 0\]</div>
<p>Para evaluar esta prueba de hipótesis debemos plantear un nuevo estadístico.</p>
<p>Antes de plantear el estadístico de prueba debemos construir los <strong>cuadrados medios</strong>.</p>
<p>Los cuadrados medios se definen <strong>como la correspondiente suma de cuadrados dividido por sus grados de libertad</strong>.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>Suma de Cuadrados</p></th>
<th class="head"><p>G.L.</p></th>
<th class="head"><p>Cuadrados Medios</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Modelo</strong></p></td>
<td><p>$<span class="math notranslate nohighlight">\(\sum(\hat{Y}_i - \bar{Y})^2\)</span>$</p></td>
<td><p>$<span class="math notranslate nohighlight">\(K-1\)</span>$</p></td>
<td><p>$<span class="math notranslate nohighlight">\(\dfrac{\sum(\hat{Y}_i - \bar{Y})^2}{K-1}\)</span>$</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Residuales</strong></p></td>
<td><p>$<span class="math notranslate nohighlight">\(\sum(Y_i - \hat Y_i)^2\)</span>$</p></td>
<td><p>$<span class="math notranslate nohighlight">\(N-K\)</span>$</p></td>
<td><p>$<span class="math notranslate nohighlight">\(\dfrac{\sum(Y_i - \hat Y_i)^2}{N-K}\)</span>$</p></td>
</tr>
<tr class="row-even"><td><p><strong>Total</strong></p></td>
<td><p>$<span class="math notranslate nohighlight">\(\sum(Y_i - \bar{Y})^2\)</span>$</p></td>
<td><p>$<span class="math notranslate nohighlight">\(N-1\)</span>$</p></td>
<td><p>$<span class="math notranslate nohighlight">\(\dfrac{\sum(Y_i - \bar{Y})^2}{N-1}\)</span>$</p></td>
</tr>
</tbody>
</table>
</div>
<p>Vamos a llamar los cuadrados medios como:</p>
<div class="math notranslate nohighlight">
\[MSR = SSR/K-1\]</div>
<div class="math notranslate nohighlight">
\[MSE = SSE/N-K\]</div>
<div class="math notranslate nohighlight">
\[MST = SST/N-1\]</div>
<p>Con base en estos estadísticos podemos calcular nuestro estadístico de prueba:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
F_{K-1,N-K} &amp;= \frac{MSR}{MSE} \\
&amp;= \frac{\frac{\sum(\hat Y_i - \bar{Y})^2}{K-1}}{\frac{\sum(Y_i - \hat Y_i)^2}{N-K}}
\end{align*}\]</div>
<p>Observe que</p>
<div class="math notranslate nohighlight">
\[MSE = \frac{\sum(Y_i - \hat Y_i)^2}{N-K} = \hat{\sigma}^2\]</div>
<p><span class="math notranslate nohighlight">\(MSE\)</span> es lo mismo que el estimador de la varianza de los errores. Entonces el <strong>error estándar del modelo</strong> es igual a:</p>
<div class="math notranslate nohighlight">
\[\hat{\sigma} = \sqrt{MSE} = \sqrt{\frac{\sum(y_i - \hat{y}_i)^2}{N-K}}\]</div>
<p>También en regresión simple:</p>
<div class="math notranslate nohighlight">
\[T^2 = F\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#Estadistico F</span>
<span class="n">MSR</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">SSR</span><span class="o">/</span><span class="p">(</span><span class="m">2-1</span><span class="p">)</span>
<span class="n">MSE</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">SSE</span><span class="o">/</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>

<span class="bp">F</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MSR</span><span class="o">/</span><span class="n">MSE</span><span class="p">;</span><span class="w"> </span>

<span class="nf">print</span><span class="p">(</span><span class="nf">paste0</span><span class="p">(</span><span class="s">&#39;Estadistico F = &#39;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="bp">F</span><span class="p">,</span><span class="w"> </span><span class="m">4</span><span class="p">)))</span>

<span class="c1">#T al cuadrado</span>
<span class="bp">T</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">b1</span><span class="o">/</span><span class="n">ee_b1</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">paste0</span><span class="p">(</span><span class="s">&#39;T-cuadrado = &#39;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="bp">T</span><span class="o">^</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">4</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estadistico F = 76.3147&quot;
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] &quot;T-cuadrado = 76.3147&quot;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">summary</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Call:
lm(formula = y ~ x)

Residuals:
       1        2        3        4        5        6 
-0.18541 -0.03343  0.90274 -0.24924  0.51064 -0.94529 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 11.57751    0.75506  15.333 0.000106 ***
x           -0.84802    0.09707  -8.736 0.000946 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.7188 on 4 degrees of freedom
Multiple R-squared:  0.9502,	Adjusted R-squared:  0.9377 
F-statistic: 76.31 on 1 and 4 DF,  p-value: 0.0009461
</pre></div>
</div>
</div>
</div>
</section>
<section id="prediccion-e-inferencia-para-hat-y-i">
<h2>Predicción e Inferencia para <span class="math notranslate nohighlight">\(\hat Y_i\)</span><a class="headerlink" href="#prediccion-e-inferencia-para-hat-y-i" title="Link to this heading">#</a></h2>
<p>Después de evaluar nuestro modelo podemos usarlo y hacer predicciones:</p>
<div class="math notranslate nohighlight">
\[\hat Y_i = \hat\beta_0 + \hat\beta_1 X_i\]</div>
<p>Es decir, a partir de las observaciones <span class="math notranslate nohighlight">\(X_i\)</span> podemos intentar predecir el valor <span class="math notranslate nohighlight">\(Y_i\)</span>.</p>
<p>Observe que <span class="math notranslate nohighlight">\(\hat Y_i\)</span> es una variable aleatoria y debemos hacer inferencia sobre este resultado.</p>
<p>Se pueden computar dos tipos de intervalos de confianza:</p>
<ol class="arabic simple">
<li><p>Un intervalo sobre la predicción media o <span class="math notranslate nohighlight">\(E(Y|X)\)</span></p></li>
<li><p>Un intervalo para hacer predicción sobre un valor individual <span class="math notranslate nohighlight">\(\hat Y_i\)</span></p></li>
</ol>
</section>
<section id="prediccion-media">
<h2>Predicción Media<a class="headerlink" href="#prediccion-media" title="Link to this heading">#</a></h2>
<p>Cuando hacemos predicción sobre la media estamos interesados en sacar un intervalo para el <span class="math notranslate nohighlight">\(E[Y_0|X_0] = \beta_0 + \beta_1 X_0 \)</span>.</p>
<p>Para esto recordemos primero que <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> es un estimador de <span class="math notranslate nohighlight">\(E[Y|X]\)</span>.</p>
<p>Necesitamos entonces la distribución de <span class="math notranslate nohighlight">\(\hat{y}_i\)</span>. Podemos demostrar que:</p>
<div class="math notranslate nohighlight">
\[\hat{y}_0 \sim N(\beta_0 + \beta_1 x_0,Var(\hat{y}_0))\]</div>
<p>Donde</p>
<div class="math notranslate nohighlight">
\[Var(\hat{y}_0) = \sigma^2 \left[ \frac{1}{n} + \frac{ (x_0 - \bar{x})^2}{\sum x_i^2}\right]\]</div>
<p>Entonces reemplazando con <span class="math notranslate nohighlight">\(s^2\)</span>, podemos construir un estimador <span class="math notranslate nohighlight">\(t\)</span> tal que:</p>
<div class="math notranslate nohighlight">
\[t_{n-K} = \frac{\hat{y}_0 - (\beta_0 + \beta_1 x_0)}{ee(\hat{y}_0)}\]</div>
<p>Podemos también sacar un IC:</p>
<div class="math notranslate nohighlight">
\[\hat{y} \pm t_{\alpha/2} ee(\hat{y}_0)\]</div>
</section>
<section id="prediccion-individual">
<h2>Predicción Individual<a class="headerlink" href="#prediccion-individual" title="Link to this heading">#</a></h2>
<p>Queremos sacar un intervalo para un punto en particular <span class="math notranslate nohighlight">\(y_0 = \beta_1 + \beta_2 x_0 + \epsilon_0\)</span></p>
<p><strong>Este intervalo va a ser más grande!</strong></p>
<p>En este caso, <span class="math notranslate nohighlight">\(\hat{y}_0\)</span> será de nuevo nuestro estimador, pero la varianza va a estar dada por la varianza del error de predicción:</p>
<div class="math notranslate nohighlight">
\[Var(y_0 - \hat{y}_0) = \sigma^2 \left[ 1 + \frac{1}{n} + \frac{ (x_0 - \bar{x})^2}{\sum x_i^2}\right]\]</div>
<p>Y el estadístico de prueba estará dado por:</p>
<div class="math notranslate nohighlight">
\[t = \frac{y_0 - \hat{y}_0}{ee(y_0 - \hat{y}_0)}\]</div>
</section>
<section id="aplicacion">
<h2>Aplicación:<a class="headerlink" href="#aplicacion" title="Link to this heading">#</a></h2>
<p>Considere la siguiente regresión sobre el precio de un vehículo usado, y una predicción de un vehículo con 40,000 Km:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\hat{p} = 6533 - 0.0312(Kilometraje) &amp; \hspace{25pt} \bar{x} = 36,009 \\
S^2 = 22983 \hspace{76pt}  &amp; \hspace{25pt} n = 100 \\
\sum x_i^2 =  4,309,340,160 \hspace{34pt} &amp; \hspace{25pt} t_{0.025} = -1.984\\
\end{align*}\]</div>
<ul class="simple">
<li><p>Calcule un intervalo de confianza (al 95%) sobre la predicción del precio de <strong>un</strong> vehículo con 40,000 km.</p></li>
</ul>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
	&amp;\hat{y} \pm t_{\alpha/2} S \sqrt{ 1 + \frac{1}{n} + \frac{ (x_0 - \bar{x})^2}{\sum x_i^2}} \\
	&amp;5,285 \pm 1.984 (151.6) \sqrt{ 1 + \frac{1}{100} + \frac{ (40000 - 36009)^2}{4,309,340,160}} \\
	&amp;5,285 \pm 303
\end{align*}\]</div>
<ul class="simple">
<li><p>Calcule un intervalo de confianza (al 95%) sobre la predicción \textbf{de un lote} de vehículos con 40,000 km cada uno.</p></li>
</ul>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
&amp;\hat{p} \pm t_{\alpha/2} S \sqrt{ \frac{1}{n} + \frac{ (x_0 - \bar{x})^2}{\sum x_i^2}} \\
&amp;5,285 \pm 1.984 (151.6) \sqrt{ \frac{1}{100} + \frac{ (40000 - 36009)^2}{4,309,340,160}} \\
&amp;5,285 \pm 35
\end{align*}\]</div>
</section>
<section id="interpretacion-de-coeficientes">
<h2>Interpretación de Coeficientes<a class="headerlink" href="#interpretacion-de-coeficientes" title="Link to this heading">#</a></h2>
<p>Uno de los supuestos del modelo de regresión lineal es que es lineal en los parámetros.</p>
<p><strong>Pero los modelos de regresión sí pueden ser no lineales en las variables</strong>.</p>
<p>La forma funcional de las variables determinará la <strong>interpretación de los parámetros</strong>.</p>
<p>Vamos a ver cuatro tipos de modelos:</p>
<ul class="simple">
<li><p>Lin-Lin</p></li>
<li><p>Log-Lin</p></li>
<li><p>Lin-log</p></li>
<li><p>Log-Log</p></li>
</ul>
</section>
<section id="lin-lin">
<h2>Lin-Lin<a class="headerlink" href="#lin-lin" title="Link to this heading">#</a></h2>
<p>Un modelo Lin-Lin es de la forma:</p>
<div class="math notranslate nohighlight">
\[X_i = \beta_0 + \beta_1 X_i + \varepsilon\]</div>
<p>Observe que si diferenciamos <span class="math notranslate nohighlight">\(Y_i\)</span> con respecto a <span class="math notranslate nohighlight">\(X_i\)</span> obtenemos</p>
<div class="math notranslate nohighlight">
\[\frac{d Y_i}{d X_i} = \beta_1\]</div>
<p><strong>Interpretación</strong>: Si <span class="math notranslate nohighlight">\(X\)</span> aumenta en 1 unidad, entonces <span class="math notranslate nohighlight">\(Y\)</span> cambia en <span class="math notranslate nohighlight">\(\beta_1\)</span> unidades.</p>
<p>Los modelos Lin-Lin son los más fáciles de interpretar</p>
</section>
<section id="log-lin">
<h2>Log-Lin<a class="headerlink" href="#log-lin" title="Link to this heading">#</a></h2>
<p>Los modelos Log -Lin son de la forma:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\ln(Y_i) &amp;= \beta_0 + \beta_1 X_i + \varepsilon_i \\
\frac{1}{Y_i}\frac{d Y_i}{d X_i} &amp;= \beta_1 \\
\frac{d Y_i/y_i}{d X_i} &amp;= \beta_1 \\		 
\frac{\Delta Y_i/Y_i}{\Delta X_i} &amp;= \beta_1 \\
\end{align*}\]</div>
<p>Otra forma de decir esto es:</p>
<div class="math notranslate nohighlight">
\[\frac{\text{Cambio relativo en Y}}{\text{Cambio absoluto en X}} = \beta_1\]</div>
<p>Note que <span class="math notranslate nohighlight">\(100*\frac{\Delta Y}{Y}\)</span> es un cambio porcentual! Entonces:</p>
<div class="math notranslate nohighlight">
\[\frac{\Delta Y_i/Y_i}{\Delta X_i} *100 = \beta_1 *100\]</div>
<p><strong>Interpretación</strong>: Ante un incremento de una unidad en X, Y cambia en <span class="math notranslate nohighlight">\(100*\beta_1\%\)</span> (<strong>semielasticidad</strong>)</p>
</section>
<section id="lin-log">
<h2>Lin-Log<a class="headerlink" href="#lin-log" title="Link to this heading">#</a></h2>
<p>Los modelos Lin-Log son de la forma:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
Y_i &amp;= \beta_0 + \beta_1 \ln(X_i) + \varepsilon_i \\
\frac{d Y_i}{d X_i} &amp;= \beta_1 \frac{1}{X_i}\\
\frac{d Y_i}{d X_i/X_i} &amp;= \beta_1 \\		 
\frac{\Delta Y_i}{\Delta X_i/X_i} &amp;= \beta_1 \\
\end{align*}\]</div>
<p>Otra forma de decir esto es:</p>
<div class="math notranslate nohighlight">
\[\frac{\text{Cambio absoluto en y}}{\text{Cambio relativo en x}} = \beta_1\]</div>
<p>Noten que <span class="math notranslate nohighlight">\(100*\frac{\Delta X}{X}\)</span> es un cambio porcentual! Entonces:</p>
<div class="math notranslate nohighlight">
\[\frac{\Delta y_i}{\Delta x_i/x_i} \frac{1}{100} = \beta_1 \frac{1}{100}\]</div>
<p><strong>Interpretación</strong> : Ante un incremento del 1% en X, Y cambia en <span class="math notranslate nohighlight">\(\frac{1}{100}*\beta_1\)</span> unidades</p>
</section>
<section id="log-log">
<h2>Log-Log<a class="headerlink" href="#log-log" title="Link to this heading">#</a></h2>
<p>El modelo Log-Log se presenta de esta forma:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\ln(y_i) &amp;= \beta_0 + \beta_1 \ln(x_i) + \epsilon_i \\
\frac{d y_i}{d x_i} \frac{1}{y_i} &amp;= \beta_1 \frac{1}{x_i} \\
\frac{d y_i}{d x_i} \frac{x_i}{y_i} &amp;= \beta_1  \text{ ¿Qué es esto?} 	
\end{align*}\]</div>
<p><strong>Interpretación</strong>: Ante un aumento en 1% en X, Y cambia en <span class="math notranslate nohighlight">\(\beta_1\%\)</span></p>
</section>
<section id="estimacion-por-maxima-verosimilitud">
<h2>Estimación por Máxima Verosimilitud<a class="headerlink" href="#estimacion-por-maxima-verosimilitud" title="Link to this heading">#</a></h2>
<p>Para estimar los coeficientes <span class="math notranslate nohighlight">\(\beta_k\)</span> también podemos usar el método de máxima verosimilitud.</p>
<p>Recuerde que asumimos que <span class="math notranslate nohighlight">\(\varepsilon_i | X \sim N(0, \sigma^2)\)</span>. Est que implica que</p>
<div class="math notranslate nohighlight">
\[Y_i | X \sim N(\mu_i, \sigma^2)\]</div>
<p>Donde <span class="math notranslate nohighlight">\(\mu_i = \beta_0 + \beta_1 X_i\)</span>. Ya que asumimos que <span class="math notranslate nohighlight">\(\varepsilon_i\)</span> y <span class="math notranslate nohighlight">\(\varepsilon_j\)</span> son independientes para todo <span class="math notranslate nohighlight">\(i\)</span> y <span class="math notranslate nohighlight">\(j\)</span>, la función de verosimilitud está dada por</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(\beta_0, \beta_1, \sigma^2) = f(Y_1, Y_2,..., Y_n) = \prod_{i = 1}^n \frac{1}{\sqrt{2\pi\sigma^2}} \exp \left\{ - \frac{1}{2\sigma^2} (Y_i - \beta_0 - \beta_1 X_i)^2 \right\}\]</div>
<p>Si tomamos el logaritmo de la función de verosimilitud obtenemos:</p>
<div class="math notranslate nohighlight">
\[\mathcal{l}(\beta_0, \beta_1, \sigma^2) =  - \frac{n}{2} \ln(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i = 1}^n (Y_i - \beta_0 - \beta_1 X_i)^2\]</div>
<p>Maximizando <span class="math notranslate nohighlight">\(\mathcal{l}(\beta_0, \beta_1, \sigma^2)\)</span> respecto a <span class="math notranslate nohighlight">\(\beta_0\)</span> y <span class="math notranslate nohighlight">\(\beta_1\)</span>, encontramos que</p>
<div class="math notranslate nohighlight">
\[\hat\beta_0 = \overline Y - \hat\beta_1 \overline X\]</div>
<div class="math notranslate nohighlight">
\[\hat\beta_1 = \frac{\sum_i (X_i - \overline X)(Y_i - \overline Y)}{\sum_i (X_i - \overline X)^2} = \frac{\mathbb{\hat Cov}(X, Y)}{\mathbb{\hat V}(X)}\]</div>
<p>Observe que estos son precisamente los estimadores que obtuvimos a través de MCO, y ya conocemos las propiedades de estos estimadores.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="0_Motivacion.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Qué es la Microeconometría?</p>
      </div>
    </a>
    <a class="right-next"
       href="4_Regresion.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Modelo de Regresión Multiple</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-simple-o-univariada">Regresión Simple o Univariada</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supuestos-del-modelo">Supuestos del Modelo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linealidad-en-parametros">Linealidad en Parámetros</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#no-multicolinealidad-o-rango-completo">No Multicolinealidad o Rango Completo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#homoscedasticidad">Homoscedasticidad</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#no-autocorrelacion">No Autocorrelación</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distribucion-normal-de-los-errores">Distribución Normal de los Errores</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#independencia-condicional-o-exogenidad">Independencia Condicional o Exogenidad</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#minimos-cuadrados-ordinarios-mco">Mínimos Cuadrados Ordinarios (MCO)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicacion-relacion-entre-aprendizaje-y-recursos-economicos">Aplicacion : Relación entre Aprendizaje y Recursos Económicos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#residuales-de-la-regresion-e-i-y-i-hat-y-i">Residuales de la Regresión: <span class="math notranslate nohighlight">\(e_i = Y_i - \hat Y_i\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#propiedades-de-los-estimadores-hat-beta-k">Propiedades de los estimadores <span class="math notranslate nohighlight">\(\hat\beta_k\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inferencia-en-regresion-simple">Inferencia en Regresión Simple</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pruebas-de-hipotesis-sobre-hat-beta-k">Pruebas de Hipótesis sobre <span class="math notranslate nohighlight">\(\hat\beta_k\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#varianza-de-hat-beta-k">Varianza de <span class="math notranslate nohighlight">\(\hat\beta_k\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#varianza-de-los-errores">Varianza de los Errores</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pruebas-de-hipotesis-individuales">Pruebas de Hipótesis Individuales</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#intervalo-de-confianza-para-beta-k">Intervalo de confianza para <span class="math notranslate nohighlight">\(\beta_k\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#coeficiente-de-determinacion-r-2">Coeficiente de Determinación: <span class="math notranslate nohighlight">\(R^2\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prueba-de-significancia-global">Prueba de Significancia Global</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prediccion-e-inferencia-para-hat-y-i">Predicción e Inferencia para <span class="math notranslate nohighlight">\(\hat Y_i\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prediccion-media">Predicción Media</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prediccion-individual">Predicción Individual</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicacion">Aplicación:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-de-coeficientes">Interpretación de Coeficientes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lin-lin">Lin-Lin</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#log-lin">Log-Lin</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lin-log">Lin-Log</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#log-log">Log-Log</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimacion-por-maxima-verosimilitud">Estimación por Máxima Verosimilitud</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Sebastian Montano
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>