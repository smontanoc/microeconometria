{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f630379e",
   "metadata": {},
   "source": [
    "# Parte II - Regresión Lineal\n",
    "\n",
    "La regresión es un método que nos permite estudiar la relación entre una variable de resultado $Y$ y una covariable o predictor $X$. \n",
    "\n",
    "Aunque no siempre se busca determinar si existe una relación causal, el problema de causalidad ocupa un lugar central en la agenda de los microeconometristas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee14862-9737-4c3f-975e-4f4992f1c469",
   "metadata": {},
   "source": [
    "## 2.1 Aplicación: Aprendizaje y Tamaño de Clase\n",
    "\n",
    "¿Cuál es la mejor forma de asignar el gasto en educación? ¿Es buena idea tener clases de menor tamaño? Estas son preguntas de interés no solo para economistas sino también para gobiernos y la sociedad en general. Sin embargo, por mucho tiempo la literatura presentó evidencia no concluyente o mixta.\n",
    "\n",
    "Parte del problema para responder estas preguntas está relacionado con que sabemos muy poco acerca de cómo aprenden los estudiantes. En particular, múltiples factores afectan los resultados de los estudiantes. Suponiendo que existe una función de producción educativa, $f$, ¿qué elementos cree usted que explican el aprendizaje?\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Aprendizaje} = f(?)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b840e7-a931-46f1-a90b-f5f9af1dd1ca",
   "metadata": {},
   "source": [
    "Existen diferentes factores que confluyen al tiempo en el aprendizaje de los estudiantes, entre ellos \n",
    "\n",
    "- Calidad docente\n",
    "- Compañeros de clase\n",
    "- Padres y condiciones del hogar\n",
    "- Infraestructura\n",
    "- Tamaño de clase\n",
    "- Habilidades innatas \n",
    "\n",
    "[Krueger (1999)](https://doi.org/10.1162/003355399556052) utilizó información de un experimento aleatario en Tennessee (STAR), encontrando que los estudiantes asignados a clases más pequeñas obtienen mejores resultados en pruebas estandarizadas y que este efecto positivo es persistente en el tiempo. Luego veremos por qué las estimaciones de Krueger pueden ser interpretadas como relaciones causales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c641f683-8529-4e00-92f7-9aa3e0d56ee6",
   "metadata": {},
   "source": [
    "## 2.2 Regresión Simple o Univariada\n",
    "\n",
    "La función de regresión, $r(X)$, resume la relación entre $X$ y $Y$: \n",
    "\n",
    "$$\n",
    "r(x) = \\mathbb{E}(Y | X = x) = \\int y f(y|x) dy.\n",
    "$$ \n",
    "\n",
    "Nuestro objetivo es estimar $r(x)$ usando datos de la forma \n",
    "\n",
    "$$\\{Y_i , X_i\\}_{i = 1}^n$$\n",
    "\n",
    "Definamos el error $\\varepsilon = Y - r(x)$. De esta manera, podemos escribir: \n",
    "\n",
    "$$\n",
    "Y = r(x) + \\varepsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2c567e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En su versión más simple, $X$ es unidimensional y asumimos que $r(x)$ es lineal. Así, \n",
    "\n",
    "$$r(x) = \\beta_0 + \\beta_1 x.$$\n",
    "\n",
    "El modelo regresión lineal simple se define como: \n",
    "\n",
    "$$\n",
    "Y_i = r(x) + \\varepsilon_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i\n",
    "$$ \n",
    "\n",
    "Observe que los parámetros desconocidos en este modelo son el intercepto $\\beta_0$ y la pendiente $\\beta_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee598d55-45f0-48d6-a97d-76d45003fa36",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.3 Supuestos del Modelo\n",
    "\n",
    "Para estimar el modelo de regresión suponemos:\n",
    "\n",
    "- Linealidad en los parámetros\n",
    "- No multicolinealidad o Rango Completo\n",
    "- Homoscedasticidad\n",
    "- No autocorrelación\n",
    "- Distribución Normal de los Errores\n",
    "- Independencia Condicional o Exogenidad\n",
    "\n",
    "Algunos de estos supuestos hace que el modelo sea **estimable**, otros nos permiten hacer **inferencia** sobre los parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34764dd6-6c98-487c-a915-9d72c6d625ca",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.3.1 Linealidad en Parámetros\n",
    "\n",
    "Este supuesto es necesario para que el modelo sea **estimable**.\n",
    "\n",
    "Se refiere a la forma funcional de la función de regresión $r(x) = \\beta_0 + \\beta_1 X_i$.\n",
    "\n",
    "Note que nos interesa estimar $\\beta_k$, no $\\beta_k^2$, $\\ln(\\beta_k)$, o cualquier otra función $g(\\beta_k)$.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<b>EJEMPLO:</b>\n",
    "<p>\n",
    "\n",
    "Suponga queremos estimar el parámetro $\\beta$ de la función $y = A X^\\beta e^\\varepsilon$. ¿Podemos usar el modelo de regresión lineal?\n",
    "\n",
    "Sí, note que podemos utilizar la siguiente transformación:\n",
    "\n",
    "$$\\ln y_i = \\alpha + \\beta \\cdot X_i + \\varepsilon_i, \\text{ con } \\alpha = \\ln A$$\n",
    "\n",
    "¿Qué pasa si $y = A X^\\beta e^\\varepsilon + u$ ?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090267e7-9f40-4e2d-8927-c1d4ce78edff",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.3.2 No Multicolinealidad o Rango Completo\n",
    "\n",
    "Este supuesto es necesario para que el modelo sea **estimable**.\n",
    "\n",
    "El supuesto hace referencia a la información que aportan diferentes covariables. En primer lugar, este supuesto señala que:\n",
    "\n",
    "$$|\\rho(X_{1i}, X_{2i})| \\neq 1$$\n",
    "\n",
    "Donde $\\rho$ es el coeficiente de correlación. Este supuesto será más relevante cuando estudiemos el modelo de regresión múltiple.\n",
    "\n",
    "Adicionalmente, es necesario que el número de observaciones en los datos $n$ sea mayor al número de parámetros $k$ que queremos estimar. Es decir\n",
    "\n",
    "$$n \\geq k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9662a0f5-46b4-4dc6-81a5-b3849acea2e5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.3.3 Homoscedasticidad\n",
    "\n",
    "Este supuesto es sobre la varianza y nos facilita realizar pruebas de hipótesis\n",
    "\n",
    "El supuesto establece que:\n",
    "\n",
    "$$V(\\varepsilon_i | X) = \\sigma^2$$\n",
    "\n",
    "La violación de este supuesto se conoce como **heteroscedasticidad**. En un modelo **heteroscedástico** \n",
    "\n",
    "$$V(\\varepsilon_i | X) = \\sigma_i^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4b4d5a",
   "metadata": {},
   "source": [
    "### 2.3.4 No Autocorrelación\n",
    "\n",
    "Este supuesto establece que:\n",
    "\n",
    "$$Cov(\\varepsilon_i, \\varepsilon_j | X) = 0 \\text{ para todo } i \\neq j$$\n",
    "\n",
    "La violación de este supuesto se conoce como **autocorrelación**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce40c906-e2d7-4097-ba54-592c02a867aa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.3.5 Distribución Normal de los Errores\n",
    "\n",
    "Este supuesto se hace sobre los errores entonces también afecta las pruebas de hipótesis.\n",
    "\n",
    "El supuesto señala que:\n",
    "\n",
    "$$\\varepsilon_i | X \\sim N(0, \\sigma^2)$$\n",
    "\n",
    "Observe que por el teorema del límite central este supuesto no es tan fuerte, y si muy útil para determinar cómo se distribuyen ciertos estadísticos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2a1ab9-9990-4ca3-94ef-eff2c9f7d932",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.3.6 Independencia Condicional o Exogenidad\n",
    "\n",
    "Para que los estimadores de $\\beta_k$ sean insesgados y consistentes suponemos que\n",
    "\n",
    "$$E(\\varepsilon_i | X) = E(\\varepsilon_i)$$\n",
    "\n",
    "Observe que combinado con el supuesto anterior tenemos que: \n",
    "\n",
    "$$E(\\varepsilon_i | X) = 0$$\n",
    "\n",
    "Según este supuesto $\\varepsilon$ es indepente de $X$. En otras palabras $X$ es una variable exogena. \n",
    "\n",
    "Este supuesto garantiza que los efectos encontrados pueden se interpretados como estimaciones **causales**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd39140",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.4 Estimación por MCO\n",
    "\n",
    "Para estimar $\\beta_0$ y $\\beta_1$ podemos usar el método de Mínimos Cuadrados Ordinarios (MCO), de manera formal: \n",
    "\n",
    "$$\\{\\hat\\beta_0, \\hat\\beta_1\\} = \\operatorname*{arg\\,min} \\mathcal{L}(\\beta_0, \\beta_1)$$\n",
    "\n",
    "donde $\\mathcal{L}(\\beta_0, \\beta_1) = \\sum_i {\\varepsilon_i}^2 = \\sum_i ({Y_i} - \\beta_0 - \\beta_1 X_i)^2$\n",
    "\n",
    "Las condiciones de primer orden (CPO) de este problema estan dadas por: \n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial\\beta_0} \\bigg|_{(\\hat\\beta_0, \\hat\\beta_1)} = \\sum_i (-2) \\cdot ({Y_i} - \\beta_0 - \\beta_1 X_i) \\bigg|_{(\\hat\\beta_0, \\hat\\beta_1)} = 0$$\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial\\beta_1} \\bigg|_{(\\hat\\beta_0, \\hat\\beta_1)} = \\sum_i (-2 X_i) \\cdot ({Y_i} - \\beta_0 - \\beta_1 X_i) \\bigg|_{(\\hat\\beta_0, \\hat\\beta_1)} = 0$$\n",
    "\n",
    "Estas ecuaciones se conocen como **ecuaciones normales**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8001c4f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A partir de estas condiciones obtenemos los siguientes **estimadores**:\n",
    "\n",
    "$$\\hat\\beta_0 = \\overline Y - \\hat\\beta_1 \\overline X$$\n",
    "\n",
    "$$\\hat\\beta_1 = \\frac{\\sum_i (X_i - \\overline X)(Y_i - \\overline Y)}{\\sum_i (X_i - \\overline X)^2} = \\frac{\\mathbb{\\hat Cov}(X, Y)}{\\mathbb{\\hat V}(X)}$$ \n",
    "\n",
    "De esta manera, la **linea ajustada** está dada por $\\hat r(x) = \\hat\\beta_0 + \\hat\\beta_1 x$, y los **valores predichos** se definen como $\\hat Y_i = \\hat r(X_i)$\n",
    "\n",
    "Definimos además el **residual** como $$e_i = Y_i - \\hat Y_i = Y_i - \\left(\\hat\\beta_0 + \\hat\\beta_1 X_i \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a920ea-d0b7-469e-a668-4e3ed55864c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.5 Aplicacion : Relación entre Aprendizaje y Crecimiento\n",
    "\n",
    "Vamos a usar datos de las pruebas PISA, que toman estudiantes de 15 años de diversos paises, para estudiar la relación entre aprendizaje y recursos económicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "904b7c4c-b305-4dd5-9eed-7b5c64dad1a5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "datos <- data.frame(\n",
    "  cnt = c(\"ALB\",\"ARE\",\"ARG\",\"AUS\",\"AUT\",\"BEL\",\"BGR\",\"BRA\",\"BRN\",\"CAN\",\"CHE\",\"CHL\",\"COL\",\"CRI\",\"CZE\",\"DEU\",\"DNK\",\"DOM\",\"ESP\",\"EST\",\"FIN\",\"FRA\",\"GBR\",\"GEO\",\"GRC\",\"GTM\",\"HKG\",\"HRV\",\"HUN\",\"IDN\",\"IRL\",\"ISL\",\"ISR\",\"ITA\",\"JAM\",\"JOR\",\"JPN\",\"KAZ\",\"KHM\",\"KOR\",\"KSV\",\"LTU\",\"LVA\",\"MAC\",\"MAR\",\"MDA\",\"MEX\",\"MKD\",\"MLT\",\"MNE\",\"MNG\",\"MYS\",\"NLD\",\"NOR\",\"NZL\",\"PAN\",\"PER\",\"PHL\",\"POL\",\"PRT\",\"PRY\",\"PSE\",\"QAT\",\"QAZ\",\"QUR\",\"ROU\",\"SAU\",\"SGP\",\"SLV\",\"SRB\",\"SVK\",\"SVN\",\"SWE\",\"TAP\",\"THA\",\"TUR\",\"URY\",\"USA\",\"UZB\",\"VNM\"),\n",
    "  math = c(368.25405,433.82986,388.54898,487.16594,490.87702,494.01554,418.33838,381.13655,440.66541,484.52203,506.45947,428.55602,390.80082,384.34594,499.37027,477.74352,478.7986,339.82878,481.86548,512.71336,475.32395,468.24401,481.82223,390.46145,433.54079,345.55713,546.03005,462.98476,479.72656,379.03128,492.17959,459.27331,457.12382,474.03372,371.40991,360.30719,534.92948,446.01273,327.40929,531.09303,352.41048,471.54378,482.58027,552.05427,363.36233,415.52394,395.40581,390.49863,468.9976,406.00521,423.92532,409.49151,491.04093,468.47831,478.87437,353.49833,394.15257,354.16683,494.4546,475.57748,340.78028,364.66173,411.98931,398.33636,444.34014,435.55027,389.20505,573.98391,345.12158,439.81693,468.62039,471.70524,482.4206,533.87613,414.58713,451.8851,409.28728,462.80969,363.90947,468.83368),\n",
    "  read = c(358.8281,419.71994,412.83373,498.79545,484.0255,481.7429,405.41276,413.32812,427.66587,490.52696,481.54308,465.12644,419.17929,415.22553,500.25072,483.0404,477.21655,353.15524,480.86845,513.84343,477.53438,467.01198,490.44853,375.03115,442.52392,375.55029,504.42272,475.74213,479.98543,372.90122,516.88935,436.02972,473.09826,480.65205,400.32092,341.46512,515.07793,404.15901,321.2015,517.97604,338.17407,466.72213,474.2778,510.36214,337.91559,412.49955,415.23693,360.23238,448.79677,405.80333,377.88235,389.52229,456.80425,476.63287,500.62093,387.40349,411.3118,345.80676,495.10716,480.06531,376.70185,348.16283,414.6251,366.71778,431.63915,436.35943,383.16603,542.47853,367.1504,440.34278,450.99055,455.30676,487.52261,504.32483,396.81118,454.84742,430.33206,501.33838,335.69292,461.27979),\n",
    "  scie = c(376.45612,434.89017,416.65516,507.91081,494.86606,494.80982,421.72777,405.9808,444.34865,500.98817,500.80958,461.86337,420.46238,410.20256,510.04275,495.53081,481.59372,361.725,491.143,528.51191,498.51606,481.40229,492.73984,385.03211,445.14657,374.28158,524.42376,482.90977,492.44187,395.31191,504.3107,447.24463,464.2001,480.90591,394.72014,373.75317,546.25504,440.96584,341.14726,531.3388,353.75366,479.50271,493.00024,543.14931,364.28557,418.00956,410.76032,381.67947,468.78635,404.08089,411.62124,417.15835,486.63188,478.18198,503.74646,383.48177,410.52702,355.28466,504.86972,487.69184,371.42047,367.63747,428.26692,381.6494,453.79679,436.78672,390.96302,560.97909,374.21203,447.30452,467.28861,486.88349,494.4219,526.40753,429.0165,475.16645,435.88107,497.41058,355.05556,472.23249),\n",
    "  econ_index = c(-.74391004,.32525118,-.67148081,.39335586,.09302247,.1154232,-.27047491,-.97523877,-.27116078,.3339245,.1809795,-.24284266,-.96515588,NA,-.01307006,-.12423293,.34054443,-.71082132,.02354851,.18467558,.19358048,-.05861012,.11972009,-.44695238,-.13303286,-1.4975343,-.45290783,-.1523256,.06026681,-1.4481847,.34413547,.38376268,.25381603,-.09725531,-.57839371,-.80391485,-.02354713,-.26977891,-2.0669077,.23721704,-.3564011,.03484754,-.00981672,-.44904569,-1.8117468,-.50431186,-.92555928,-.26902116,.04917327,-.1922437,-.73720841,-.66233746,.23876144,.52544167,.22389294,-.96079427,-1.1207972,-1.3333803,-.06879525,-.2048969,-1.2130009,-.91617362,.11453604,-.46005621,-.29700884,-.28406969,-.27803347,.29037254,-1.3106626,-.20093189,-.25804407,.15198116,.33239471,-.28002015,-.96258429,-1.2274957,-.81679644,.04198107,-.68010732,-1.3159208)\n",
    ")\n",
    "datos <- na.omit(datos)\n",
    "plot(datos$econ_index, datos$read, xlab  = \"Economic Index\", ylab = \"Reading Test Scores - PISA 2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3b1419f-7759-4dc2-8581-38c74b306688",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = read ~ econ_index, data = datos)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-98.150 -20.616   3.319  24.557  91.063 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  460.878      5.218  88.331  < 2e-16 ***\n",
       "econ_index    68.896      7.821   8.809  2.8e-13 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 39.54 on 77 degrees of freedom\n",
       "Multiple R-squared:  0.5019,\tAdjusted R-squared:  0.4955 \n",
       "F-statistic:  77.6 on 1 and 77 DF,  p-value: 2.797e-13\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model <- lm(read ~ econ_index, data = datos)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b928462-5b16-4283-b57f-6d006e85190f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 5 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>yhat</th><th scope=col>lwr</th><th scope=col>upr</th><th scope=col>se</th><th scope=col>df</th><th scope=col>residuals</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>409.6258</td><td>395.3168</td><td>423.9347</td><td>5.417594</td><td>77</td><td>39.54123</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>483.2867</td><td>465.0712</td><td>501.5022</td><td>6.896686</td><td>77</td><td>39.54123</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>414.6158</td><td>401.1048</td><td>428.1269</td><td>5.115512</td><td>77</td><td>39.54123</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>487.9789</td><td>468.6670</td><td>507.2907</td><td>7.311772</td><td>77</td><td>39.54123</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>467.2871</td><td>452.4118</td><td>482.1624</td><td>5.632037</td><td>77</td><td>39.54123</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 5 × 6\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & yhat & lwr & upr & se & df & residuals\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 409.6258 & 395.3168 & 423.9347 & 5.417594 & 77 & 39.54123\\\\\n",
       "\t2 & 483.2867 & 465.0712 & 501.5022 & 6.896686 & 77 & 39.54123\\\\\n",
       "\t3 & 414.6158 & 401.1048 & 428.1269 & 5.115512 & 77 & 39.54123\\\\\n",
       "\t4 & 487.9789 & 468.6670 & 507.2907 & 7.311772 & 77 & 39.54123\\\\\n",
       "\t5 & 467.2871 & 452.4118 & 482.1624 & 5.632037 & 77 & 39.54123\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 5 × 6\n",
       "\n",
       "| <!--/--> | yhat &lt;dbl&gt; | lwr &lt;dbl&gt; | upr &lt;dbl&gt; | se &lt;dbl&gt; | df &lt;int&gt; | residuals &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 1 | 409.6258 | 395.3168 | 423.9347 | 5.417594 | 77 | 39.54123 |\n",
       "| 2 | 483.2867 | 465.0712 | 501.5022 | 6.896686 | 77 | 39.54123 |\n",
       "| 3 | 414.6158 | 401.1048 | 428.1269 | 5.115512 | 77 | 39.54123 |\n",
       "| 4 | 487.9789 | 468.6670 | 507.2907 | 7.311772 | 77 | 39.54123 |\n",
       "| 5 | 467.2871 | 452.4118 | 482.1624 | 5.632037 | 77 | 39.54123 |\n",
       "\n"
      ],
      "text/plain": [
       "  yhat     lwr      upr      se       df residuals\n",
       "1 409.6258 395.3168 423.9347 5.417594 77 39.54123 \n",
       "2 483.2867 465.0712 501.5022 6.896686 77 39.54123 \n",
       "3 414.6158 401.1048 428.1269 5.115512 77 39.54123 \n",
       "4 487.9789 468.6670 507.2907 7.311772 77 39.54123 \n",
       "5 467.2871 452.4118 482.1624 5.632037 77 39.54123 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Prediccion\n",
    "model_fit <- as.data.frame(predict(model, se.fit = TRUE, , interval = \"confidence\",  data = datos, level = 0.99))\n",
    "names(model_fit) <- c('yhat', 'lwr', 'upr', 'se', 'df', 'residuals')\n",
    "head(model_fit, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8fd7b62",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAAAAAP9NTU1oaGh8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\nCAkQICRA4D/kjr0LGrsx6AAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(datos$econ_index, datos$read, xlab  = \"Economic Index\", ylab = \"Reading Test Scores - PISA 2022\")\n",
    "lines(datos$econ_index, model_fit$yhat, col = \"blue\", lwd=2, lty = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8accf660-e75e-4f2d-9f67-fe9b6d7f072e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.6 Residuales de la Regresión: $e_i = Y_i - \\hat Y_i$\n",
    "\n",
    "Observe que a partir de las ecuaciones normales tenemos que \n",
    "\n",
    "$$\\sum_i ({Y_i} - \\hat\\beta_0 - \\hat\\beta_1 X_i) = \\sum_i e_i = 0$$\n",
    "\n",
    "$$\\sum_i (X_i) \\cdot ({Y_i} - \\hat\\beta_0 - \\hat\\beta_1 X_i) = \\sum_i e_i \\cdot X_i = 0$$\n",
    "\n",
    "Lo anterior indica que:\n",
    "\n",
    "$$\\frac{\\sum_i e_i}{n} = \\bar e = 0 \\hspace{5pt} \\Rightarrow \\hspace{5pt} \\bar Y = \\bar{\\hat Y}$$\n",
    "\n",
    "$$\\sum_i e_i \\cdot X_i = 0 \\hspace{5pt} \\Rightarrow \\hspace{5pt} \\mathbb{\\hat Cov}(e_i, X_i) = \\sum_i (e_i - \\bar e) \\cdot (X_i - \\bar X) = 0$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f40475a1-8f73-4490-b51d-eba670f4d8d1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAABNTU1oaGh8fHyM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\nQmCC",
      "text/plain": [
       "Plot with title \"Histogram of e\""
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Predecir los errores\n",
    "e <- datos$read - model_fit$yhat\n",
    "\n",
    "#Estimacion de la función de densidad\n",
    "hist(e, prob = T)\n",
    "lines(density(e), lty = 2, lw = 2, col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704bd3c5-d620-48dd-a438-3d5abf8713de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.7 Propiedades de los estimadores $\\hat\\beta_k$\n",
    "\n",
    "Queremos evaluar si $\\hat\\beta_1$ es un buen estimador de $\\beta_1$. \n",
    "\n",
    "La primera pregunta que nos hacemos es ¿$E(\\hat\\beta_1) = \\beta_1$? Es decir, queremos ver si $\\hat\\beta_1$ es un estimador insesgado.\n",
    "\n",
    "Note que \n",
    "\n",
    "\\begin{align*}\n",
    "    \\hat\\beta_1 & = \\frac{\\sum_i (X_i - \\overline X)(Y_i - \\overline Y)}{\\sum_i (X_i - \\overline X)^2}\\\\\n",
    "     & = \\frac{\\sum_i (X_i - \\overline X)(\\beta_0 + \\beta_1 X_i + \\varepsilon_i - \\beta_0 - \\beta_1 \\bar X - \\bar \\varepsilon)}{\\sum_i (X_i - \\overline X)^2}\\\\\n",
    "    & = \\beta_1 + \\frac{\\sum_i (X_i - \\overline X)(\\varepsilon_i - \\overline \\varepsilon)}{\\sum_i (X_i - \\overline X)^2}\\\\\n",
    "    & = \\beta_1 + \\frac{\\sum_i (X_i - \\overline X) \\cdot \\varepsilon_i}{\\sum_i (X_i - \\overline X)^2} \\\\     \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350bf85b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Si tomamos la esperanza de esta exprensión tenemos:\n",
    "\n",
    "\\begin{align*}\n",
    "    E(\\hat\\beta_1) & = \\beta_1 + E \\left(\\frac{\\sum_i (X_i - \\overline X) \\cdot \\varepsilon_i}{\\sum_i (X_i - \\overline X)^2}\\right) \\\\    \n",
    "\\end{align*}\n",
    "\n",
    "A partir del supuesto de **independencia condicional**, para todo $i$ y $j$, $\\varepsilon_i$ y $X_j$ son independientes. Es decir,\n",
    "\n",
    "$$E(\\varepsilon_i \\cdot X_j) = E(\\varepsilon_i) \\cdot E(X_j) = 0$$\n",
    "\n",
    "Debido a esto:\n",
    "\n",
    "$$E\\left(\\sum_i (X_i - \\overline X) \\cdot \\varepsilon_i\\right) = \\sum_i E(X_i \\varepsilon_i) - \\sum_i E(\\overline X \\varepsilon_i) = \\sum_i E(X_i) E(\\varepsilon_i) - \\sum_i E(\\overline X) E(\\varepsilon_i) = 0$$\n",
    "\n",
    "De esta manera, el estimador $\\hat\\beta_1$, que obtuvimos por el método MCO, es insesgado. Así,\n",
    "\n",
    "$$E(\\hat\\beta_1) = \\beta_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcb6cd2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Es $\\beta_0$ un estimador insesgado?\n",
    "\n",
    "\\begin{align*}\n",
    "    E(\\hat\\beta_0) & =E \\left(\\overline Y - \\hat\\beta_1 \\overline X \\right)\\\\\n",
    "     & = E\\left(\\beta_0 + \\beta_1 \\overline X + \\overline\\varepsilon - \\hat\\beta_1 \\overline X\\right)\\\\\n",
    "     & = \\beta_0 + \\beta_1 E(\\overline X) + E(\\overline\\varepsilon) - \\beta_1 E(\\overline X)\\\\\n",
    "     & = \\beta_0 \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3705a4a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.8 Inferencia en Regresión Simple\n",
    "\n",
    "Luego de estimar el modelo, y saber que en promedio nuestros estimadores de MCO encuentran los verdaderos parámetros que se desconocen, queremos determinar si \n",
    "\n",
    "1. existe una relación **estádisticamente significativa** entre $Y$ y $X$ \n",
    "2. nuestro modelo tiene un buen ajuste (o poder predictivo)\n",
    "\n",
    "Con este objetivo en mente, \n",
    "\n",
    "1. realizaremos pruebas de hipotesis individuales y conjuntas\n",
    "2. computaremos el coeficiente de determinación $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0667a9d2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.8.1 Pruebas de Hipótesis sobre $\\hat\\beta_k$\n",
    "\n",
    "Debido al supuesto de **normalidad de los errores**, $\\varepsilon_i | X \\sim N(0, \\sigma^2)$, es posible probar que \n",
    "\n",
    "$$\\hat\\beta_k | X \\sim N(\\beta_k, \\sigma^2_\\beta)$$\n",
    "\n",
    "Sin entrar en detalles, recuerde que la suma de variables normales da como resultado una variable que se distribuye normal. Esta es la idea fundamental detrás de la demostración de que nuestros estimadores de MCO son normales.\n",
    "\n",
    "La hipotesis que queremos considerar en general toma la siguiente forma:\n",
    "\n",
    "$$H_0 : \\beta_k = 0$$\n",
    "$$H_1 : \\beta_k \\neq 0$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f845d18f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note que bajo la hipótesis nula ($H_0$) el parámetro $\\beta_k$ es cero, y queremos saber si podemos rechazar dicha hipotesis con un nivel de significancia $\\alpha \\in \\{0.1, 0.05, 0.01\\}$.\n",
    "\n",
    "Para probar esta hipótesis podemoslos usar el siguiente estadístico:\n",
    "\n",
    "$$\\frac{\\hat\\beta_k - \\beta_k}{\\sigma_\\beta}$$\n",
    "\n",
    "Sin embargo, desconocemos $\\sigma_\\beta$. Esto implica que debemos estimarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9957bc01",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.8.2 Varianza de $\\hat\\beta_k$\n",
    "\n",
    "Recuerde $\\hat\\beta_1 = \\frac{\\mathbb{\\hat Cov}(X, Y)}{\\mathbb{\\hat V}(X)} = \\beta_1 + \\frac{\\sum_i (X_i - \\overline X) \\cdot \\varepsilon_i}{\\sum_i (X_i - \\overline X)^2}$. De esta manera,\n",
    "\n",
    "\\begin{align*}\n",
    "    V(\\hat\\beta_1 | X) & = E \\left(\\hat\\beta_1 - E(\\hat\\beta_1) | X \\right)^2 = E \\left(\\hat\\beta_1 - \\beta_1 | X \\right)^2 = E \\left(\\frac{\\sum_i (X_i - \\overline X) \\cdot \\varepsilon_i}{\\sum_i (X_i - \\overline X)^2} | X \\right)^2 \\\\ \n",
    "    & = \\left(\\frac{1}{\\sum_i (X_i - \\overline X)^2}\\right)^2 E \\left(\\sum_i (X_i - \\overline X) \\cdot \\varepsilon_i | X \\right)^2 \\\\\n",
    "    & = \\left(\\frac{1}{\\sum_i (X_i - \\overline X)^2}\\right)^2 E \\left(\\sum_i (X_i - \\overline X)^2 \\cdot \\varepsilon_i^2 + 2 \\sum_{i < j} (X_i - \\overline X) (X_j - \\overline X) \\varepsilon_i \\varepsilon_j | X \\right) \\\\\n",
    "    & = \\left(\\frac{1}{\\sum_i (X_i - \\overline X)^2}\\right)^2 \\left(\\sum_i (X_i - \\overline X)^2 \\cdot E(\\varepsilon_i^2 | X) \\right) \\\\ \n",
    "    & = \\frac{\\sigma^2}{\\sum_i (X_i - \\overline X)^2} = \\frac{\\sigma^2}{S^2_X (n-1)} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Note que para estimar esta varianza debemos encontrar un estimador para $\\sigma^2$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e04fe84",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.8.3 Varianza de los Errores\n",
    "\n",
    "Antes de encontrar un estimador para $\\sigma^2$, note que\n",
    "\n",
    "\\begin{align*}\n",
    "    V(Y_i | X_i) & = V(\\beta_0 + \\beta_1 X_i + \\varepsilon_i | X) \\\\\n",
    "    & = V(\\beta_0 + \\beta_1 X_i | X) + V(\\varepsilon_i | X) + 2 \\cdot Cov(\\beta_0 + \\beta_1 X_i, \\varepsilon_i | X) \\\\\n",
    "    & = V(\\varepsilon_i | X) = \\sigma^2 \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Más aún, observe que \n",
    "\n",
    "$$Y_i | X \\sim N(\\beta_0 + \\beta_1 X_i, \\sigma^2)$$\n",
    "\n",
    "Ahora, ya que $E(\\varepsilon_i) = 0$, podemos mostrar que \n",
    "\n",
    "$$V(\\varepsilon_i | X) = E(\\varepsilon_i^2)$$\n",
    "\n",
    "Un estimador para $\\sigma^2$ es:\n",
    "\n",
    "$$\\hat\\sigma^2 = \\frac{\\sum_i e_i^2}{n-K} = \\frac{\\sum_i (Y_i - \\hat Y_i)^2}{n-K} = \\frac{\\sum_i (Y_i - \\hat\\beta_0 - \\hat\\beta_1 X_i)^2}{n-K} $$\n",
    "\n",
    "Donde $K$ es el número de parámetros que debemos estimar. En este caso $K = 2$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bf166a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.8.4 Pruebas de Hipótesis Individuales\n",
    "\n",
    "Para nuestra prueba de hipótesis \n",
    "\n",
    "$$H_0 : \\beta_1 = 0$$\n",
    "$$H_1 : \\beta_1 \\neq 0$$\n",
    "\n",
    "Usaremos el siguiente estadístico de prueba\n",
    "\n",
    "$$T = \\frac{\\hat\\beta_1 - \\beta_1}{\\text{ee}(\\hat\\beta_1)}$$\n",
    "\n",
    "Donde el error estandar de $\\hat\\beta_1$ se define como:\n",
    "\n",
    "$$\\text{ee}(\\hat\\beta_1) = \\sqrt{ \\frac{\\sum_i e_i^2/n-K}{\\sum_i (X_i - \\overline X)^2}}$$\n",
    "\n",
    "Observe que nuestro estadístico $T \\sim t_{n-K}$. Esto se debe a que $\\hat\\beta_1 \\sim N(\\beta_1, \\sigma_{\\beta_1})$ y $\\sum_i e_i^2 \\sim \\chi^2_{n-K}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07523498",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.8.4 Intervalo de confianza para $\\beta_k$\n",
    "\n",
    "Nuestro intervalo de confianza para el parámetro desconocido $\\beta_k$ está dado por \n",
    "\n",
    "\\begin{align*}\n",
    "    IC & = \\left(\\beta_k - t_{\\alpha/2 \\hspace{2pt},\\hspace{2pt} n-K}\\cdot\\sqrt{ \\frac{\\sum_i e_i^2/n-K}{\\sum_i (X_i - \\overline X)^2}} \\hspace{5pt} , \\hspace{5pt} \\beta_k + t_{\\alpha/2 \\hspace{2pt},\\hspace{2pt} n - K}\\cdot\\sqrt{ \\frac{\\sum_i e_i^2/n-K}{\\sum_i (X_i - \\overline X)^2}} \\right)\n",
    "\\end{align*}\n",
    "\n",
    "Cuando $n$ es grande, si $\\alpha = 0.05$, entonces $|t_{\\alpha/2 \\hspace{2pt},\\hspace{2pt} n-K}| \\approx 1.96$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a186eaa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.8.5 Coeficiente de Determinación: $R^2$\n",
    "\n",
    "Una segunda forma de evaluar nuestro modelo es sabiendo qué tanto de $\\boldsymbol{Y}$ puede $\\boldsymbol{X}$ explicar.\n",
    "\n",
    "Para saber esto debemos hacer lo siguiente:\n",
    "\\begin{align*}\n",
    "Y_i  &= \\hat Y_i + e_i \\\\\n",
    "Y_i -\\bar{Y} &= \\hat Y_i -\\bar{Y} + e_i \\\\\n",
    "\\sum_i (Y_i -\\bar{Y})^2 &= \\sum_i (\\hat Y_i -\\bar{Y} + e_i)^2 \\\\\n",
    "\\sum_i (Y_i -\\bar{Y})^2 &= \\sum_i (\\hat Y_i -\\bar{Y})^2 + \\sum_i e_i^2 + 2 \\sum_i e_i (\\hat Y_i -\\bar{Y}) \\\\\n",
    "\\sum_i (Y_i -\\bar{Y})^2 &= \\sum_i (\\hat Y_i -\\bar{Y})^2 + \\sum_i e_i^2\n",
    "\\end{align*}\n",
    "    \n",
    "Esto es así porque\n",
    "\n",
    "\\begin{align*}\n",
    "\\sum_i e_i (\\hat Y_i -\\bar{Y}) &= \\sum_i e_i \\hat Y_i - \\bar{Y}\\sum e_i \\\\\n",
    "&= \\sum_i e_i(\\hat \\beta_0 + \\hat \\beta_1 X_i) - \\bar{Y}\\sum e_i = 0\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3776757",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Es decir, a partir de nuestros estimadores de MCO\n",
    "\n",
    "\\begin{align*}\n",
    "\\underbrace{\\sum_i (Y_i -\\bar{Y})^2}_{\\text{Varianza Total } (SST)} &= \\sum_i (\\hat Y_i -\\bar{Y})^2 + \\sum_i e_i^2 \\\\\n",
    "&= \\underbrace{\\sum_i (\\hat Y_i -\\bar{Y})^2}_{\\text{Varianza Explicada } (SSR)} + \\underbrace{\\sum_i (Y_i - \\hat Y_i)^2}_{\\text{Varianza No Explicada } (SSE)}\n",
    "\\end{align*}\n",
    "\n",
    "Luego podemos definir:\n",
    "\n",
    "\\begin{align*}\n",
    "R^2 &= \\frac{SSR}{SST} = 1 - \\frac{SSE}{SST} \\\\\n",
    "&= \\frac{\\sum_i (\\hat Y_i -\\bar{Y})^2}{\\sum_i (Y_i -\\bar{Y})^2} = 1 - \\frac{\\sum_i (Y_i - \\hat Y_i)^2}{\\sum_i (Y_i -\\bar{Y})^2}\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807c24d4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Observe que el coeficiente de determinación está acodato, es decir,\n",
    "\n",
    "$$0 \\leq R^2 \\leq 1$$\n",
    "\n",
    "Este estadístico **mide qué tanto de la varianza de $Y$ es explicada por la covariable $X$** \n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"> \n",
    "<b>Nota:</b>\n",
    "<p>\n",
    "\n",
    "En el modelo de regresión lineal, el coeficiente de determinación crece a medida que se incluyen más variables explicativas o covariables.\n",
    "</div>\n",
    "\n",
    "Para el modelo de regresión simple podemos demostar que \n",
    "\n",
    "$$\\rho_{Y,X}^2 = R^2$$\n",
    "\n",
    "donde $\\rho_{Y,X}$ es el coeficiente de correlación entre $X$ y $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464115c3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.8.6 Prueba de Significancia Global\n",
    "\n",
    "La idea de esta prueba es evaluar si todas las covariables que incluimos en el modelo pueden explicar conjuntamente la variable $Y$\n",
    "\n",
    "La prueba de signifiancia global se define como:\n",
    "\n",
    "$$H_0 : \\beta_1 = \\beta_2 = ... = \\beta_K = 0$$\n",
    "$$H_1 : \\text{ al menos un } \\beta_k \\text{ es diferente de 0}$$\n",
    "\n",
    "Esta es una prueba de 'cola derecha,' por lo tanto la zona de rechazo siempre va a ser a la derecha e igual a $\\alpha$.\n",
    "\n",
    "Observe que en el modelo de regresión univariada (o simple), esta prueba es equivalente a:\n",
    "\n",
    "$$H_0 : \\beta_1 = 0$$\n",
    "$$H_1 : \\beta_1 \\neq 0$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddb17c3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Para evaluar esta prueba de hipótesis debemos plantear un nuevo estadístico. \n",
    "\n",
    "Antes de plantear el estadístico de prueba debemos construir los **cuadrados medios**.\n",
    "\n",
    "Los cuadrados medios se definen **como la correspondiente suma de cuadrados dividido por sus grados de libertad**.\n",
    "\n",
    "\n",
    "|             | Suma de Cuadrados                        | G.L.   | Cuadrados Medios                                         |\n",
    "|-------------|-------------------------------------------|--------|----------------------------------------------------------|\n",
    "| **Modelo**  | $$\\sum(\\hat{Y}_i - \\bar{Y})^2$$             | $$K-1$$  | $$\\dfrac{\\sum(\\hat{Y}_i - \\bar{Y})^2}{K-1}$$               |\n",
    "| **Residuales** | $$\\sum(Y_i - \\hat Y_i)^2$$                | $$N-K$$  | $$\\dfrac{\\sum(Y_i - \\hat Y_i)^2}{N-K}$$                   |\n",
    "| **Total**      | $$\\sum(Y_i - \\bar{Y})^2$$                  | $$N-1$$  | $$\\dfrac{\\sum(Y_i - \\bar{Y})^2}{N-1}$$                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0407cda",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Vamos a llamar los cuadrados medios como:\n",
    "\n",
    "$$MSR = SSR/K-1$$\n",
    "\n",
    "$$MSE = SSE/N-K$$\n",
    "\n",
    "$$MST = SST/N-1$$\n",
    "\n",
    "Con base en estos estadísticos podemos calcular nuestro estadístico de prueba:\n",
    "\t\n",
    "\\begin{align*}\n",
    "F_{K-1,N-K} &= \\frac{MSR}{MSE} \\\\\n",
    "&= \\frac{\\frac{\\sum(\\hat Y_i - \\bar{Y})^2}{K-1}}{\\frac{\\sum(Y_i - \\hat Y_i)^2}{N-K}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5a613b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Observe que \n",
    "\n",
    "$$MSE = \\frac{\\sum(Y_i - \\hat Y_i)^2}{N-K} = \\hat{\\sigma}^2$$\n",
    "\n",
    "$MSE$ es lo mismo que el estimador de la varianza de los errores. Entonces el **error estándar del modelo** es igual a:\n",
    "\n",
    "$$\\hat{\\sigma} = \\sqrt{MSE} = \\sqrt{\\frac{\\sum(y_i - \\hat{y}_i)^2}{N-K}}$$\n",
    "\n",
    "También en regresión simple:\n",
    "\n",
    "$$T^2 = F$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae70d6b0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.8.7 Predicción e Inferencia para $\\hat Y_i$\n",
    "\n",
    "Después de evaluar nuestro modelo podemos usarlo y hacer predicciones:\n",
    "\n",
    "$$\\hat Y_i = \\hat\\beta_0 + \\hat\\beta_1 X_i$$\n",
    "\n",
    "Es decir, a partir de las observaciones $X_i$ podemos intentar predecir el valor $Y_i$.\n",
    "\n",
    "Observe que $\\hat Y_i$ es una variable aleatoria y debemos hacer inferencia sobre este resultado.\n",
    "\n",
    "Se pueden computar dos tipos de intervalos de confianza:\n",
    "\n",
    "1. Un intervalo sobre la predicción media o $E(Y|X)$\n",
    "\n",
    "2. Un intervalo para hacer predicción sobre un valor individual $\\hat Y_i$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e695f56",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.8.8 Predicción Media\n",
    "\n",
    "Cuando hacemos predicción sobre la media estamos interesados en sacar un intervalo para el $E[Y_0|X_0] = \\beta_0 + \\beta_1 X_0 $.\n",
    "\n",
    "Para esto recordemos primero que $\\hat{y}_i$ es un estimador de $E[Y|X]$.\n",
    "\n",
    "Necesitamos entonces la distribución de $\\hat{y}_i$. Podemos demostrar que:\n",
    "\n",
    "$$\\hat{y}_0 \\sim N(\\beta_0 + \\beta_1 x_0,Var(\\hat{y}_0))$$\n",
    "\n",
    "Donde \n",
    "\n",
    "$$Var(\\hat{y}_0) = \\sigma^2 \\left[ \\frac{1}{n} + \\frac{ (x_0 - \\bar{x})^2}{\\sum x_i^2}\\right]$$\n",
    "\n",
    "Entonces reemplazando con $s^2$, podemos construir un estimador $t$ tal que:\n",
    "\n",
    "$$t_{n-K} = \\frac{\\hat{y}_0 - (\\beta_0 + \\beta_1 x_0)}{ee(\\hat{y}_0)}$$\n",
    "\n",
    "Podemos también sacar un IC:\n",
    "\n",
    "$$\\hat{y} \\pm t_{\\alpha/2} ee(\\hat{y}_0)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b775e16",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.8.9 Predicción Individual\n",
    "\n",
    "Queremos sacar un intervalo para un punto en particular $y_0 = \\beta_1 + \\beta_2 x_0 + \\epsilon_0$\n",
    "\n",
    "**Este intervalo va a ser más grande!**\n",
    "\n",
    "En este caso, $\\hat{y}_0$ será de nuevo nuestro estimador, pero la varianza va a estar dada por la varianza del error de predicción:\n",
    "\n",
    "$$Var(y_0 - \\hat{y}_0) = \\sigma^2 \\left[ 1 + \\frac{1}{n} + \\frac{ (x_0 - \\bar{x})^2}{\\sum x_i^2}\\right]$$\n",
    "\n",
    "Y el estadístico de prueba estará dado por:\n",
    "\n",
    "$$t = \\frac{y_0 - \\hat{y}_0}{ee(y_0 - \\hat{y}_0)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e163cec-555c-4bc1-8fc6-a328727a5568",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.9 Estimación por Máxima Verosimilitud\n",
    "\n",
    "Para estimar los coeficientes $\\beta_k$ también podemos usar el método de máxima verosimilitud.\n",
    "\n",
    "Recuerde que asumimos que $\\varepsilon_i | X \\sim N(0, \\sigma^2)$. Est que implica que \n",
    "\n",
    "$$Y_i | X \\sim N(\\mu_i, \\sigma^2)$$\n",
    "\n",
    "Donde $\\mu_i = \\beta_0 + \\beta_1 X_i$. Ya que asumimos que $\\varepsilon_i$ y $\\varepsilon_j$ son independientes para todo $i$ y $j$, la función de verosimilitud está dada por \n",
    "\n",
    "$$\\mathcal{L}(\\beta_0, \\beta_1, \\sigma^2) = f(Y_1, Y_2,..., Y_n) = \\prod_{i = 1}^n \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp \\left\\{ - \\frac{1}{2\\sigma^2} (Y_i - \\beta_0 - \\beta_1 X_i)^2 \\right\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811f666d-924b-4fd5-a787-d3db5448a6a0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Si tomamos el logaritmo de la función de verosimilitud obtenemos:\n",
    "\n",
    "$$\\mathcal{l}(\\beta_0, \\beta_1, \\sigma^2) =  - \\frac{n}{2} \\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i = 1}^n (Y_i - \\beta_0 - \\beta_1 X_i)^2$$\n",
    "\n",
    "Maximizando $\\mathcal{l}(\\beta_0, \\beta_1, \\sigma^2)$ respecto a $\\beta_0$ y $\\beta_1$, encontramos que\n",
    "\n",
    "$$\\hat\\beta_0 = \\overline Y - \\hat\\beta_1 \\overline X$$\n",
    "\n",
    "$$\\hat\\beta_1 = \\frac{\\sum_i (X_i - \\overline X)(Y_i - \\overline Y)}{\\sum_i (X_i - \\overline X)^2} = \\frac{\\mathbb{\\hat Cov}(X, Y)}{\\mathbb{\\hat V}(X)}$$ \n",
    "\n",
    "Observe que estos son precisamente los estimadores que obtuvimos a través de MCO, y ya conocemos las propiedades de estos estimadores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdcc1de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.10 Modelo de Regresión Multiple\n",
    "\n",
    "Un modelo de regresión con múltiples covariables o predictores se puede escribir de la siguiente manera:\n",
    "\n",
    "$$y_i = \\beta_0 + \\beta_1 x_{1,i} + ... + \\beta_{k-1} x_{k-1, i} + \\varepsilon_i$$\n",
    "\n",
    "Observe que queremos estimar $k$ parámetros (incluyendo a $\\beta_0$), usando $k-1$ covariables a partir de una base de datos con $n$ observaciones \n",
    "\n",
    "$$\\{y_i, x_{1,i}, x_{2,i}, ..., x_{k-1,i}\\}_{i=1}^n$$\n",
    "\n",
    "Pero antes de derivar los estimadores de los parámetros $\\beta_j$, veamos una aplicación:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a58b1f-f3af-4af5-aaf0-e174778ac730",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.10.1 Modelo en Forma Matricial\n",
    "\n",
    "En forma matricial, nuestro modelo de regresión se puede escribir de la siguiente forma:\n",
    "\n",
    "$$Y = X\\beta + \\varepsilon$$\n",
    "\n",
    "Observe que tenemos cuatro matrices:\n",
    "\n",
    "$$\n",
    "Y_{[n \\times 1]} = X_{[n \\times k]} \\, \\beta_{[k \\times 1]} + \\varepsilon_{[n \\times 1]}\n",
    "$$ \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_n\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 & x_{11} & x_{21} & \\dots & x_{k-1,1} \\\\\n",
    "1 & x_{12} & x_{22} & \\dots & x_{k-1,2} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "1 & x_{1n} & x_{2n} & \\dots & x_{k-1,n}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\beta_0 \\\\\n",
    "\\beta_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\beta_{k-1}\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "\\varepsilon_1 \\\\\n",
    "\\varepsilon_2 \\\\\n",
    "\\vdots \\\\\n",
    "\\varepsilon_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "La forma matricial es una manera útil de presentar $n$ **ecuaciones**, ya que:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_n\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\beta_0 + \\sum_j^{k-1} \\beta_j x_{j1} + \\varepsilon_1 \\\\\n",
    "\\beta_0 + \\sum_j^{k-1} \\beta_j x_{j2} + \\varepsilon_2 \\\\\n",
    "\\vdots \\\\\n",
    "\\beta_0 + \\sum_j^{k-1} \\beta_j x_{jn} + \\varepsilon_n\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8058694b-bc3d-428f-9efa-a2b9160aa32a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.10.2 Supuestos en forma Matricial\n",
    "\n",
    "¿Cómo se ven los supuestos sobre el error cuando tenemos matrices?\n",
    "\n",
    "$$\n",
    "\\varepsilon \\varepsilon' =\n",
    "\\begin{bmatrix}\n",
    "\\varepsilon_1 \\\\\n",
    "\\varepsilon_2 \\\\\n",
    "\\vdots \\\\\n",
    "\\varepsilon_n\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\varepsilon_1 & \\varepsilon_2 & \\dots & \\varepsilon_n\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\varepsilon_1^2 & \\varepsilon_1\\varepsilon_2 & \\dots & \\varepsilon_1\\varepsilon_n \\\\\n",
    "\\varepsilon_2\\varepsilon_1 & \\varepsilon_2^2 & \\dots & \\varepsilon_2\\varepsilon_n \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\varepsilon_n\\varepsilon_1 & \\varepsilon_n\\varepsilon_2 & \\dots & \\varepsilon_n^2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Observe que bajo homoscedasticidad y no autocorrelación:\n",
    "\n",
    "$$\n",
    "E[\\varepsilon \\varepsilon'] =\n",
    "\\begin{bmatrix}\n",
    "\\sigma^2 & 0 & \\dots & 0 \\\\\n",
    "0 & \\sigma^2 & \\dots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & \\dots & \\sigma^2\n",
    "\\end{bmatrix}\n",
    "= \\sigma^2 I_n\n",
    "$$\n",
    "\n",
    "Si asumimos independencia condicional y además que los errores son normales, entonces:\n",
    "\n",
    "$$E(\\varepsilon | x_1, ...., x_{k-1}) = E(\\varepsilon | X) = 0$$\n",
    "\n",
    "$$\\varepsilon \\sim N(0, \\sigma^2 I_n)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7fae7e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.11 Mínimos Cuadrados Ordinarios\n",
    "\n",
    "Antes de derivar nuestros estimadores de mínimos cuadrados usando matrices, veremos que es posible encontrar los estimadores de manera similar que en el caso de regresión simple. Nuestro modelo está dado por:\n",
    "\n",
    "$$y_i = \\beta_0 + \\sum_{j = 1}^{k-1} \\beta_j x_{j,i} + \\varepsilon_i$$\n",
    "\n",
    "Así, definimos la función de perdida cómo:\n",
    "\n",
    "$$\\mathcal{L}(\\beta_0, ..., \\beta_{k-1}) = \\sum_i^n \\varepsilon_i^2 = \\sum_i^n \\left(y_i - \\beta_0 - \\sum_{j = 1}^{k-1} \\beta_j x_{j,i} \\right)^2$$\n",
    "\n",
    "Para encontrar los estimadores de MCO para $\\beta_0, ..., \\beta_{k-1}$ debemos resolver el siguiente problema:\n",
    "\n",
    "$$\\min_{\\beta_0, ..., \\beta_{k-1}} \\mathcal{L}(\\beta_0, ..., \\beta_{k-1}) = \\sum_i^n \\varepsilon_i^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67116b9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Las condiciones de primer orden para este problema están dadas por:\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial\\beta_0} \\bigg|_{\\hat\\beta} = \\sum_i (-2) \\cdot ({y_i} - \\beta_0 - \\sum_{j = 1}^{k-1} \\beta_j x_{j,i}) \\bigg|_{\\hat\\beta} = 0$$\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial\\beta_1} \\bigg|_{\\hat\\beta} = \\sum_i (-2 x_{1,i}) \\cdot ({y_i} - \\beta_0 \\sum_{j = 1}^{k-1} \\beta_j x_{j,i}) \\bigg|_{\\hat\\beta} = 0$$\n",
    "\n",
    "$$\\vdots$$\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial\\beta_{k-1}} \\bigg|_{\\hat\\beta} = \\sum_i (-2 x_{k-1,i}) \\cdot ({y_i} - \\beta_0 - \\sum_{j = 1}^{k-1} \\beta_j x_{j,i}) \\bigg|_{\\hat\\beta} = 0$$\n",
    "\n",
    "Observe que tenemos $k$ ecuaciones para estimar $k$ parámetros. \n",
    "\n",
    "Lo anterior nos permite concluir que este sistema de ecuaciones tiene solución. Sin embargo, solucionarlo alegabraicamente puede ser bastante tedioso. Por esta razón usaremos matrices. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a96176a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.12 Estimación de $\\beta$\n",
    "\n",
    "Observe que matricialmente podemos escribir\n",
    "\n",
    "$$\n",
    "\\varepsilon' \\varepsilon =\n",
    "\\begin{bmatrix}\n",
    "\\varepsilon_1 & \\varepsilon_2 & \\dots & \\varepsilon_n\n",
    "\\end{bmatrix}_{1 \\times n}\n",
    "\\begin{bmatrix}\n",
    "\\varepsilon_1 \\\\\n",
    "\\varepsilon_2 \\\\\n",
    "\\vdots \\\\\n",
    "\\varepsilon_n\n",
    "\\end{bmatrix}_{\\hspace{2pt} n \\times 1} = \n",
    "\\varepsilon_1^2 + \\varepsilon_2^2 + ... + \\varepsilon_n^2 =\n",
    "\\sum_{i = 1}^n \\varepsilon_i^2\n",
    "$$\n",
    "\n",
    "Luego nuestro problema de minimización se puede reescribir de la siguiente manera:\n",
    "\n",
    "$$\\min_\\beta \\varepsilon'\\varepsilon = \\min_\\beta (Y - X\\beta)'(Y - X\\beta) = \\min_\\beta Y'Y - 2\\beta'X'Y + \\beta' X'X\\beta$$\n",
    "\n",
    "Nota: $Y'X\\beta = \\beta'X'Y$ ya que son escalares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d72dbb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Las condiciones de primer orden están dadas por \n",
    "\n",
    "$$\\frac{\\partial\\mathcal{(\\varepsilon'\\varepsilon)}}{\\partial\\beta} \\bigg|_{\\beta = \\hat \\beta} = -2 X'Y + 2 X'X\\hat\\beta = 0$$\n",
    "\n",
    "Esto es así porque $\\frac{\\partial(X'Y)'\\beta}{\\partial\\beta} = X'Y$, $\\frac{\\partial \\beta' X'X\\beta}{\\partial\\beta} = (X'X + (X'X)')\\beta = 2X'X\\beta$\n",
    "\n",
    "De esta manera, el estimador de MCO para $\\beta$ es \n",
    "\n",
    "$$\\hat\\beta = (X'X)^{-1}(X'Y)$$\n",
    "\n",
    "Observe que a partir de las condiciones de primer orden podemos determinar que\n",
    "\n",
    "$$0 = X'Y - X'X\\hat\\beta = X'(Y - X'X\\hat\\beta) = X'e$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c7fe6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.12.1 Matrices y Sumatorias\n",
    "\n",
    "La matriz $(X'X)^{-1}$ es conocida usalmente como **matriz de información**. Observe que\n",
    "\n",
    "$$\n",
    "X'X =\n",
    "\\begin{bmatrix}\n",
    "n & \\sum_i x_{1i} & \\sum_i x_{2i} & \\sum_i x_{3i} & \\cdots & \\sum_i x_{k-1, i} \\\\\n",
    "\\sum_i x_{1i} & \\sum_i x_{1i}^2 & \\sum_i x_{1i}x_{2i} & \\sum_i x_{1i}x_{3i} & \\cdots & \\sum_i x_{1i}x_{k-1,i} \\\\\n",
    "\\sum_i x_{2i} & \\sum_i x_{2i}x_{1i} & \\sum_i x_{2i}^2 & \\sum_i x_{2i}x_{3i} & \\cdots & \\sum_i x_{2i}x_{k-1,i} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\sum_i x_{k-1,i} & \\sum_i x_{k-1,i}x_{1i} & \\sum_i x_{k-1,i}x_{2i} & \\sum_i x_{k-1,i}x_{3i} & \\cdots & \\sum_i x_{k-1,i}^2\n",
    "\\end{bmatrix} \\hspace{5pt},\\hspace{5pt} X'Y =\n",
    "\\begin{bmatrix}\n",
    "\\sum_i y_i \\\\\n",
    "\\sum_i x_{1i}y_i \\\\\n",
    "\\sum_i x_{2i}y_i \\\\\n",
    "\\vdots \\\\\n",
    "\\sum_i x_{k-1,i}y_i\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1ef406",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.12.2 Ejemplo\n",
    "\n",
    "Usando los siguientes datos queremos estimar el modelo $Y = X\\beta + \\varepsilon$, donde $\\beta = [\\beta_0,  \\beta_1]'$ :\n",
    "\n",
    "$$\n",
    "Y =\n",
    "\\begin{bmatrix}\n",
    "8 \\\\\n",
    "9 \\\\\n",
    "4 \\\\\n",
    "2 \\\\\n",
    "7 \\\\\n",
    "3 \\\\\n",
    "\\end{bmatrix} \\hspace{2pt},\\hspace{2pt} X =\n",
    "\\begin{bmatrix}\n",
    "1 & 4 \\\\\n",
    "1 & 3 \\\\\n",
    "1 & 10 \\\\\n",
    "1 & 11 \\\\\n",
    "1 & 6 \\\\\n",
    "1 & 9 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "A partir de esta información debemos calcular las siguientes matrices:\n",
    "\n",
    "$$\n",
    "X'X =\n",
    "\\begin{bmatrix}\n",
    "6 & 43 \\\\\n",
    "43 & 363 \\\\\n",
    "\\end{bmatrix} \\hspace{2pt},\\hspace{2pt} (X'X)^{-1} = \\frac{1}{329} \\cdot\n",
    "\\begin{bmatrix}\n",
    "363 & -43 \\\\\n",
    "-43 & 6 \\\\\n",
    "\\end{bmatrix} \\hspace{2pt},\\hspace{2pt} X'Y =\n",
    "\\begin{bmatrix}\n",
    "33 \\\\\n",
    "190 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Recuerde que nuestro estimador de $\\beta$ es $\\hat \\beta = (X'X)^{-1}X'Y$. Así,\n",
    "\n",
    "$$\n",
    "\\hat\\beta = \\frac{1}{329} \\cdot\n",
    "\\begin{bmatrix}\n",
    "363 & -43 \\\\\n",
    "-43 & 6 \\\\\n",
    "\\end{bmatrix} \\cdot\n",
    "\\begin{bmatrix}\n",
    "33 \\\\\n",
    "190 \\\\\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "11.5775076 \\\\\n",
    "-0.8480243 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c9bae48",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 1 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>x1</th><td>11.5775076</td></tr>\n",
       "\t<tr><th scope=row>x2</th><td>-0.8480243</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 1 of type dbl\n",
       "\\begin{tabular}{r|l}\n",
       "\tx1 & 11.5775076\\\\\n",
       "\tx2 & -0.8480243\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 1 of type dbl\n",
       "\n",
       "| x1 | 11.5775076 |\n",
       "| x2 | -0.8480243 |\n",
       "\n"
      ],
      "text/plain": [
       "   [,1]      \n",
       "x1 11.5775076\n",
       "x2 -0.8480243"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y <- c(8, 9, 4, 2, 7, 3)\n",
    "x1 <- c(1, 1, 1, 1, 1, 1)\n",
    "x2 <- c(4, 3, 10, 11, 6, 9)\n",
    "X <- cbind(x1, x2)\n",
    "\n",
    "XX <- t(X)%*%X\n",
    "XX1 = solve(XX)\n",
    "XY <- t(X)%*%Y\n",
    "\n",
    "b = XX1%*%XY; b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4beedc1f-29ad-4ac3-aad5-6e768ae16dc1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = Y ~ x2)\n",
       "\n",
       "Residuals:\n",
       "       1        2        3        4        5        6 \n",
       "-0.18541 -0.03343  0.90274 -0.24924  0.51064 -0.94529 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) 11.57751    0.75506  15.333 0.000106 ***\n",
       "x2          -0.84802    0.09707  -8.736 0.000946 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.7188 on 4 degrees of freedom\n",
       "Multiple R-squared:  0.9502,\tAdjusted R-squared:  0.9377 \n",
       "F-statistic: 76.31 on 1 and 4 DF,  p-value: 0.0009461\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(lm(Y ~ x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4eda4b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.13 Propiedades de $\\hat\\beta$\n",
    "\n",
    "Mostremos ahora $E(\\hat\\beta) = \\beta$. Observe que\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat\\beta &= (X'X)^{-1}X'Y \\\\\n",
    "&= (X'X)^{-1}X'(X\\beta + \\varepsilon) \\\\\n",
    "&= (X'X)^{-1}X'X\\beta + (X'X)^{-1}X'\\varepsilon) \\\\\n",
    "&= \\beta + (X'X)^{-1}X'\\varepsilon \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Luego, es fácil ver que \n",
    "\n",
    "$$E(\\hat\\beta | X) = \\beta + (X'X)^{-1}X'E(\\varepsilon | X)$$\n",
    "\n",
    "Por el supuesto de independencia condicional $E(\\varepsilon | X) = 0$. Lo que implica que $E(\\hat\\beta | X) = \\beta$\n",
    "\n",
    "Por la ley de esperanzas iteradas podemos demostrar que\n",
    "\n",
    "$$E[E(\\hat\\beta | X)] = E[\\hat\\beta] = \\beta$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9524a51",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.14 Matriz de Varianza y Covarianza\n",
    "\n",
    "Ahora queremos determinar la varianza de $\\hat\\beta$, en forma matricial procedemos de la siguiente manera:\n",
    "\n",
    "\\begin{align*}\n",
    "V(\\hat{\\beta}|X ) &= E \\big[(\\hat{\\beta} - E[\\hat{\\beta}])(\\hat{\\beta} - E[\\hat{\\beta}])' \\,|\\, X \\big] \\\\\n",
    "&= E \\big[(\\beta + (X'X)^{-1}X'\\varepsilon - \\beta])(\\beta + (X'X)^{-1}X'\\varepsilon - \\beta])' \\,|\\, X \\big] \\\\\n",
    "&= E \\big[((X'X)^{-1}X'\\varepsilon)((X'X)^{-1}X'\\varepsilon)' \\,|\\, X \\big] \\\\\n",
    "&= E \\big[(X'X)^{-1}X'\\varepsilon\\varepsilon'X(X'X)^{-1} \\,|\\, X \\big] \\\\\n",
    "&= (X'X)^{-1}X' E[\\varepsilon\\varepsilon'|X] X (X'X)^{-1} \\\\\n",
    "&= (X'X)^{-1}X' \\sigma^2 I X (X'X)^{-1} \\\\\n",
    "&=\\sigma^2 (X'X)^{-1}X'X (X'X)^{-1} \\\\\n",
    "&= \\sigma^2 (X'X)^{-1}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103b4ae4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Observe que la solución anterior no solo nos permite encontrar las varianzas para cada $\\hat\\beta_j$, $j \\in \\{0, 1, ..., k-1\\}$, sino también la covarianza entre $\\hat\\beta_j$ y $\\hat\\beta_l$ para todo $j \\neq l$. Es decir,\n",
    "\n",
    "$$\n",
    "V(\\hat{\\beta} | X) =\n",
    "\\begin{bmatrix}\n",
    "Var(\\hat{\\beta}_0) & Cov(\\hat{\\beta}_0, \\hat{\\beta}_1) & \\dots & Cov(\\hat{\\beta}_0, \\hat{\\beta}_K) \\\\\n",
    "Cov(\\hat{\\beta}_1, \\hat{\\beta}_0) & Var(\\hat{\\beta}_1) & \\dots & Cov(\\hat{\\beta}_1, \\hat{\\beta}_K) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "Cov(\\hat{\\beta}_K, \\hat{\\beta}_0) & Cov(\\hat{\\beta}_K, \\hat{\\beta}_1) & \\dots & Var(\\hat{\\beta}_K)\n",
    "\\end{bmatrix} = \\sigma^2 (X'X)^{-1}\n",
    "$$\n",
    "\n",
    "Recuerde que un estimador para $\\sigma^2$ es:\n",
    "\n",
    "$$\\hat\\sigma^2 = \\frac{\\sum_i e_i^2}{n-k} = \\frac{e'e}{n-k}$$\n",
    "\n",
    "Entonces,\n",
    "\n",
    "$$\\widehat{V(\\hat{\\beta} | X)} = \\frac{e'e}{n-k}(X'X)^{-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216030b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.15 Pruebas de Significancia Individual\n",
    "\n",
    "Para evaluar nuestro modelo, podemos considerar pruebas de hipótesis individuales para cada uno de los parámetros desconocidos $\\beta_j$. Es decir, para todo $j \\in \\{0, ..., k-1\\}$ evaluamos:\n",
    "\n",
    "$$H_0 : \\beta_j = 0$$\n",
    "$$H_1 : \\beta_j \\neq 0$$\n",
    "\n",
    "Ya que asumimos que $\\varepsilon  \\sim N\\left(0, \\sigma^2 I\\right)$, nuestros estimadores $\\hat\\beta \\sim N\\left(\\beta, \\sigma^2(X'X)^{-1}\\right)$. Así, para evaluar nuestra hipótesis podemos usar el estadístico de prueba:\n",
    "\n",
    "$$T = \\frac{\\hat\\beta_j}{\\text{ee}(\\hat\\beta_j)} \\sim t_{n-k}$$\n",
    "\n",
    "Observe que $\\text{ee}(\\hat\\beta_j)$ se puede computar a partir de la matriz $\\hat\\sigma^2 (X'X)^{-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0282e89f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En nuestro ejemplo anterior\n",
    "\n",
    "$$\n",
    "Y = [8, 9, 4, 2, 7, 3]' \\hspace{5pt},\\hspace{5pt}\n",
    "(X'X)^{-1} = \\frac{1}{329} \\cdot\n",
    "\\begin{bmatrix}\n",
    "363 & -43 \\\\\n",
    "-43 & 6 \\\\\n",
    "\\end{bmatrix} \\hspace{5pt},\\hspace{5pt} \\hat\\beta =\n",
    "\\begin{bmatrix}\n",
    "11.58 \\\\\n",
    "-0.85 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Usando esta información podemos calcular:\n",
    "\n",
    "$$\\hat Y = X\\hat\\beta = [8.18, 9.03, 3.10, 2.25, 6.49, 3.94]$$\n",
    "\n",
    "$$e = Y - \\hat Y = [-0.18, -0.03, 0.90, -0.25, 0.51, -0.94]$$\n",
    "\n",
    "$$\\hat\\sigma^2=\\frac{e'e}{6-2} = 0.516 \\hspace{5pt},\\hspace{5pt} \\widehat{V(\\hat\\beta)} = \\hat\\sigma^2 \\cdot (X'X)^{-1} = \\frac{1}{329} \\cdot\n",
    "\\begin{bmatrix}\n",
    "363 & -43 \\\\\n",
    "-43 & 6 \\\\\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "0.570 & -0.0675 \\\\\n",
    "-0.0675 & 0.009 \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Luego, ee$(\\beta_0) = \\sqrt{0.570} = 0.7551$, ee$(\\beta_1) = \\sqrt{0.009} = 0.0971$, $Cov(\\beta_0, \\beta_1) = -0.0675$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8338c6c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.16 Bondad de Ajuste: $R^2$ y $R^2$-Ajustado\n",
    "\n",
    "Al igual que en el caso de regresión simple, definimos \n",
    "\n",
    "\\begin{align*}\n",
    "R^2 &= \\frac{\\sum_i (\\hat y_i -\\bar{y})^2}{\\sum_i (y_i -\\bar{y})^2} = 1 - \\frac{\\sum_i (y_i - \\hat y_i)^2}{\\sum_i (y_i -\\bar{y})^2} \\\\\n",
    "&= \\frac{SSR}{SST} = 1 - \\frac{SSE}{SST} \n",
    "\\end{align*}\n",
    "\n",
    "Sin embargo, $R^2$ **aumentará siempre que incluyamos una covariable adicional**. Incluso si dicha covariable es 'ruido'.\n",
    "\n",
    "En el caso de regresión múltiple definimos un coeficiente 'penaliza' el poder predictivo del modelo cuando incluimos variables irrelevantes:\n",
    "\n",
    "$$R^2\\text{- ajustado} = 1 - \\frac{SSE\\hspace{2pt}/\\hspace{2pt}(n-k)}{SST\\hspace{2pt}/\\hspace{2pt}(n-1)}$$\n",
    "\n",
    "Observe que al incluir una variable irrelevante, los residuales de nuestro modelo $e_i = y_i - \\hat y_i$ no cambiarán de manera considerable (con respecto al modelo que no incluye ruido). Sin embargo, ahora estamos dividiendo $SSE$ por $n-k$ (que penaliza el número de parámetros que queremos estimar). \n",
    "\n",
    "Así, mientras $R^2$ aumenta con el número de variables, $R^2$-ajustado puede disminuir. Veamos un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9be222a5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(mf, parent.frame()): objeto 'wage1' no encontrado\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(mf, parent.frame()): objeto 'wage1' no encontrado\nTraceback:\n",
      "1. lm(log(wage) ~ educ + exper + expersq + female, data = wage1)",
      "2. eval(mf, parent.frame())",
      "3. eval(mf, parent.frame())",
      "4. stats::model.frame(formula = log(wage) ~ educ + exper + expersq + \n .     female, data = wage1, drop.unused.levels = TRUE)",
      "5. model.frame.default(formula = log(wage) ~ educ + exper + expersq + \n .     female, data = wage1, drop.unused.levels = TRUE)",
      "6. is.data.frame(data)",
      "7. .handleSimpleError(function (cnd) \n . {\n .     watcher$capture_plot_and_output()\n .     cnd <- sanitize_call(cnd)\n .     watcher$push(cnd)\n .     switch(on_error, continue = invokeRestart(\"eval_continue\"), \n .         stop = invokeRestart(\"eval_stop\"), error = NULL)\n . }, \"objeto 'wage1' no encontrado\", base::quote(eval(mf, parent.frame())))"
     ]
    }
   ],
   "source": [
    "summary(lm(log(wage) ~ educ + exper + expersq + female, data = wage1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0104919d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "n <- length(wage1$wage)\n",
    "wage1$noise <- runif(n, 0, 1)\n",
    "summary(lm(log(wage) ~ educ + exper + expersq + female + noise, data = wage1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307ea0c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.17 Prueba de Signifiancia Global\n",
    "\n",
    "Al igual que en el caso de regresión simple, queremos evaluar el modelo de manera conjunta. Para ello consideramos la siguiente prueba de hipótesis:\n",
    "\n",
    "$$H_0: \\beta_1 = \\beta_2 = ... = \\beta_{k-1}$$\n",
    "$$H_1: \\beta_j \\neq 0 \\text{ para cualquier } j \\in \\{1, ..., k-1\\}$$\n",
    "\n",
    "Nuestro estadístico de prueba para evaluar esta hipótesis es:\n",
    "\n",
    "$$F = \\frac{MSR}{MSE} = \\frac{SSR/(k-1)}{SSE/(n-k)} = \\frac{\\sum_i(\\hat y_i - \\bar{y})^2/(k-1)}{\\sum_i(y_i - \\hat y_i)^2/(n-k)} \\sim F_{k-1,n-k}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3673cad1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.18 Otras Pruebas de Hipotesis\n",
    "\n",
    "En el modelo multivariado podemos evaluar hipótesis para cuaquier (sub-)conjunto de parámetros. Algunos ejemplos son:\n",
    "\n",
    "Sean $j, l, t \\in \\{0, 1, ..., k-1\\}$ y $c_1, c_2, c_3 \\in \\mathbb{R}$, \n",
    "\n",
    "$$H_0: \\beta_j = \\beta_{l} + c_1$$\n",
    "$$H_0: \\beta_j + \\beta_{l} = \\beta_{t}$$\n",
    "$$H_0: \\beta_j = c_1\\beta_l + c_2 \\beta_t + c_3$$\n",
    "\n",
    "A continuación presentamos dos estadísticos de prueba con los cuales podemos evaluar nuestras hipótesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859baf4b-d6e9-4223-a392-d0b9a9493383",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.18.1 Estadístico T\n",
    "\n",
    "Para la prueba \n",
    "\n",
    "$$H_0: \\beta_j = \\beta_{l} + c_1$$\n",
    "$$H_1: \\beta_j \\neq \\beta_{l} + c_1$$\n",
    "\n",
    "Podemos usar el estadístico \n",
    "\n",
    "$$T = \\frac{\\hat\\beta_j - \\hat\\beta_l - c_1}{\\text{ee}(\\hat\\beta_j - \\hat\\beta_l - c_1)} = \\frac{\\hat\\beta_j - \\hat\\beta_l - c_1}{\\sqrt{Var(\\hat\\beta_j) + Var(\\hat\\beta_l) - 2Cov(\\hat\\beta_j, \\hat\\beta_l)}} \\sim t_{n-k}$$\n",
    "\n",
    "Observe que el error estandar de esta prueba lo podemos calcular a partir de la matrix de varianza-covarianza: $V(\\hat\\beta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8765684",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.19 Minimos Cuadrados Restringidos\n",
    "\n",
    "Este tipo de pruebas también se pueden hacer usando una regresión auxiliar a la cual se aplica la restricción.  \n",
    "\n",
    "Suponga que tenemos el siguiente modelo:\n",
    "\n",
    "$$\n",
    "y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{3i} + \\beta_4 x_{4i} + \\varepsilon_i\n",
    "$$\n",
    "\n",
    "Nos interesa evaluar:\n",
    "\n",
    "$$\n",
    "H_0 : \\beta_1 = \\beta_3 = 0\n",
    "$$\n",
    "\n",
    "Entonces el modelo restringido sería:\n",
    "\n",
    "$$\n",
    "y_i = \\beta_0 + \\beta_2 x_{2i} + \\beta_4 x_{4i} + \\varepsilon_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37217ff9-a377-4dcf-ac94-f47335af95ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hay varias formas de evaluar estas pruebas sin usar la matriz $R$.\n",
    "\n",
    "Sin embargo, todas requieren de una regresión auxiliar donde usemos la restricción.  \n",
    "\n",
    "Los estadísticos que podemos usar son:\n",
    "\n",
    "\\begin{align*}\n",
    "F_{J,n-K} &= \\frac{R^2_{NR} - R^2_{R}}{J} \\Big/ \\frac{(1 - R^2_{NR})}{n-k} \\\\\n",
    "&= \\frac{SSE_{R} - SSE_{NR}}{J} \\Big/ \\frac{SSE_{NR}}{n-k} \\\\\n",
    "&= \\frac{e'_{R}e_{R} - e'_{NR}e_{NR}}{J} \\Big/ \\frac{e'_{NR}e_{NR}}{n-k} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Todas estas son fórmulas equivalentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29505a1-22e3-4afb-a043-99cdfbaa88e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Modelo No Restringido\n",
    "summary(lm(Y ~ x2 + x3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba120346-562a-4230-81b9-f7ef1ba9bbb7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Modelo Restringido\n",
    "summary(lm(Y ~ x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efd772e-e89a-4b5c-b681-2a2d1faee3a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.19.1 Ejemplo\n",
    "\n",
    "Calculemos el estadístico F asociado a la prueba $H_0: \\beta_2 = 0$\n",
    "\n",
    "\\begin{align*}\n",
    "F_{J,n-K} &= \\frac{R^2_{NR} - R^2_{R}}{J} \\Big/ \\frac{(1 - R^2_{NR})}{n-k} \\\\\n",
    "&= \\frac{0.9521 - 0.9502}{1} \\Big/ \\frac{(1 - 0.9521)}{3} \\approx 0.12\n",
    "\\end{align*}\n",
    "\n",
    "Tambien lo podemos calcular de la siguiente manera:\n",
    "\n",
    "\\begin{align*}\n",
    "F_{J,n-K} &= \\frac{SSE_{R} - SSE_{NR}}{J} \\Big/ \\frac{SSE_{NR}}{n-k} \\\\ \\\\\n",
    "&= \\frac{2.067 - 1.987}{1} \\Big/ \\frac{(1.987)}{3} \\approx 0.12\n",
    "\\end{align*}\n",
    "\n",
    "Observe que: \n",
    "\n",
    "$$SSE_{NR} = MSE_{NR}*(n-k) = 0.8138^2 * (6-3) = 1.987$$ \n",
    "$$SSE_{R} = MSE_{R}*(n-k) = 0.7188^2 * (6-2) = 2.067$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e9c285",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.19.2 Selección de Variables\n",
    "\n",
    "Este método es útil para saber qué variables deben entrar y cuáles no en un modelo.\n",
    "\n",
    "1. Corremos el modelo completo.  \n",
    "2. Identificamos las variables que no son significativas o que tienen coeficientes raros.  \n",
    "3. Excluimos esas variables, y corremos el modelo sin ellas.  \n",
    "4. Hacemos una prueba F tal que:  \n",
    "\n",
    "$$\n",
    "H_0 : \\beta_{exc} = 0\n",
    "$$\n",
    "\n",
    "$\\hspace{15pt}$ donde $\\beta_{exc}$ son los betas excluidos.  \n",
    "\n",
    "5. Si se rechaza $H_0$, entonces ese grupo de variables se debe dejar.  \n",
    "6. De lo contrario, las podemos sacar del modelo.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698e96dd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.20 Variables Binarias y Categoricas\n",
    "\n",
    "Hay muchas variables que no podemos incluir linealmente a un modelo porque son cualitativas. Sin embargo, podemos incluir variables categóricas.  \n",
    "\n",
    "Ejemplos: género, recibe subsidio o no, máximo nivel educativo, etc.  \n",
    "\n",
    "Para ello creamos variables binarias (tambien conocidas como variables *dummy*):\n",
    "\n",
    "$$\n",
    "D_i = 1(\\text{Genero}_i = \\text{mujer}) = \n",
    "\\begin{cases} \n",
    "1 & \\text{si mujer} \\\\ \n",
    "0 & \\text{si hombre} \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "En nuestra matrix $X$ estas variables se representan a traves de vectores de 1 y 0. Por ejemplo:\n",
    "\n",
    "$$\n",
    "X =\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 4 \\\\\n",
    "1 & 1 & 5.6 \\\\\n",
    "1 & 0 & 8.9 \\\\\n",
    "1 & 1 & 3.2 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887f6e84",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Las variables categóricas son fáciles de incluir en un modelo.  \n",
    "\n",
    "Para interpretar estas variables debemos considerar la **categoría excluida**.\n",
    "\n",
    "- Si hay $m$ categorías, entonces podemos incluir solo $m - 1$ variables binarias.\n",
    "\n",
    "- De lo contrario, habría **colinealidad perfecta** (con el vector de 1s asociado al intercepto del modelo) y el modelo no se podría estimar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2037fd9-bd42-4b1e-8c7d-b6dff37088a2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.21 Aplicación\n",
    "\n",
    "Consideremos la siguiente extensión del modelo minceriano:\n",
    "\n",
    "$$\\log(w_i) = \\beta_0 + \\beta_1 s_i + \\beta_2 x_i + \\beta_3 x_i^2 + \\beta_4 f_i + \\sum_{j=2}^4 \\mu_j 1(\\text{Occup}_i = j) + \\varepsilon_i$$\n",
    "\n",
    "Donde $\\text{Occup}_i$ es la ocupacion del individuo $i$. \n",
    "\n",
    "Observe que la sumatoria no inicia en la categoria 1 porque debemos fijar una **grupo de comparación**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae7847-7e32-4592-8302-fd24db258673",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "wage1$occup <- 1; wage1$occup[wage1$profocc==1] <- 2; wage1$occup[wage1$clerocc==1] <- 3; wage1$occup[wage1$servocc==1] <- 4\n",
    "summary(lm(log(wage) ~ educ + exper + expersq + female + I(occup==2) + I(occup==3) + I(occup==4) + I(occup==1), data = wage1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f54de17",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "summary(lm(log(wage) ~ educ + exper + expersq + female + factor(occup), data = wage1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2d1920",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.22 Interacciones\n",
    "\n",
    "Las variables binarias son una muy buena herramienta.\n",
    "\n",
    "- Una aplicación muy útil son las **interacciones**.\n",
    "\n",
    "- Una interacción es simplemente el **producto de una variable** (categórica o no) con una variable categórica.\n",
    "\n",
    "- Las interacciones permiten medir **cambios en pendiente** y diferenciar grupos por varias características.\n",
    "\n",
    "Considere el siguiente modelo:\n",
    "\n",
    "$$\\log(w_i) = \\beta_0 + \\beta_1 f_i + \\beta_2 c_i + \\beta_3 s_i + \\varepsilon_i$$\n",
    "\n",
    "Donde \n",
    "\n",
    "- $w_i$ es el salario del individuo $i$, $s_i$ los años de educación\n",
    "\n",
    "- $f_i$ toma el valor de 1 si es mujer, y $c_i$ toma el valor de 1 si está casado (o casada)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b548b250",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.22.1 Interacción entre Variables Binarias\n",
    "\n",
    "La interacción entre $f_i$ y $c_i$ nos permitirá diferenciar las **mujeres casadas**.\n",
    "\n",
    "$$\\log(w_i) = \\beta_0 + \\beta_1 f_i + \\beta_2 c_i + \\beta_3 s_i + \\delta (f_i \\times c_i) + \\varepsilon_i$$\n",
    "\n",
    "Observe que:\n",
    "\n",
    "$$\\Delta_{f_i=0}(c_i)  = E[\\log(w_i) \\mid f_i = 0, c_i = 1] - E[\\log(w_i) \\mid f_i = 0, c_i = 0] = \\beta_2$$\n",
    "\n",
    "$$\\Delta_{f_i=1}(c_i) = E[\\log(w_i) \\mid f_i = 1, c_i = 1] - E[\\log(w_i) \\mid f_i = 1, c_i = 0] = \\beta_2 + \\delta$$\n",
    "\n",
    "Entonces,\n",
    "\n",
    "$$\\delta = \\Delta_{f_i=1}(c_i) - \\Delta_{f_i=0}(c_i)$$\n",
    "\n",
    "- $\\beta_2$: cambio en el salario para hombres casados (vs hombres solteros)\n",
    "- $\\beta_2$ + $\\delta$: cambio en el salario para mujeres casadas (vs mujeres solteras)\n",
    "- $\\delta$: cambio diferencial en el salario para mujeres casadas (vs al cambio para hombres casados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c7ba7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "summary(lm(log(wage) ~ female + married + educ + female*married, data = wage1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b386d6b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.22.2 Interacción entre una Variable Binaria y una Continua\n",
    "\n",
    "Considere ahora la interacción entre una variable categórica y una variable continua.\n",
    "\n",
    "Esto identifica **cambios en pendientes** o efectos diferenciados.  \n",
    "\n",
    "$$\\log(w_i) = \\beta_0 + \\beta_1 f_i + \\beta_2 s_i + \\beta_3 (f_i \\times s_i) + \\varepsilon_i$$\n",
    "\n",
    "Podemos calcular la derivada:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\log(w_i)}{\\partial s_i} = \\beta_2 + \\beta_3 f_i\n",
    "$$\n",
    "\n",
    "- $\\beta_2$: efecto de la educación en el salario de los **hombres**.  \n",
    "- $\\beta_2 + \\beta_3$: efecto de la educación en el salario promedio de las **mujeres**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073eed50",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "summary(lm(log(wage) ~ female + educ + female*educ, data = wage1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680e5912",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.23 Teorema de Gauss-Markov\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TEOREMA:</b>\n",
    "<p>\n",
    "\n",
    "El estimador de Mínimos Cuadrados Ordinarios $\\hat{\\beta} = (X'X)^{-1}X'Y$ es el **mejor estimador lineal insesgado (MELI)**.  \n",
    "\n",
    "</div>\n",
    "\n",
    "- Esto significa que es el estimador lineal más **eficiente** o con menor varianza\n",
    "- Esto ocurre **si y solo si** se cumplen los supuestos del modelo lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057e3ebb-9f97-4ea9-9e44-3f700af3301e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.23.1 Demostación del Teorema de Gauss-Markov\n",
    "\n",
    "Considere un estimador lineal insesgado $b$, tal que:\n",
    "\n",
    "$$b = CY \\quad \\text{y} \\quad C \\neq (X'X)^{-1}X'$$\n",
    "\n",
    "De forma genérica podemos definir:\n",
    "\n",
    "$$\n",
    "C = (D + A) \\quad \\text{tal que} \\quad A = (X'X)^{-1}X'\n",
    "$$\n",
    "\n",
    "Entonces:\n",
    "\n",
    "\\begin{align*}\n",
    "b &= CY = DY + AY \\\\\n",
    "&= D(X\\beta + \\varepsilon) + \\hat{\\beta}\n",
    "\\end{align*}\n",
    "\n",
    "Como $b$ es insesgado:\n",
    "\n",
    "$$\n",
    "E[b|X] = \\beta\n",
    "$$\n",
    "\n",
    "$$\n",
    "E[b|X] = DX\\beta + D \\cdot E[\\varepsilon|X] + E[\\hat{\\beta}|X]\n",
    "$$\n",
    "\n",
    "Entonces debe cumplirse que:\n",
    "\n",
    "$$\n",
    "DX = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f8f877-27e7-4c36-977d-5dd55e884700",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Podemos entonces escribir lo siguiente:\n",
    "\n",
    "\\begin{align*}\n",
    "b &= DX\\beta + D\\varepsilon + \\hat{\\beta} \\\\\n",
    "&= D\\varepsilon + \\beta + A\\varepsilon \\\\\n",
    "&= \\beta + (D + A)\\varepsilon\n",
    "\\end{align*}\n",
    "\n",
    "Ahora saquemos la varianza de este estimador:\n",
    "\n",
    "\\begin{align*}\n",
    "Var(b) = (D + A)Var(\\varepsilon)(D + A)' \\\\\n",
    "&= \\sigma^2 (D + A)(D + A)' \\\\\n",
    "&= \\sigma^2[DD' + DA' + AD' + AA'] \\\\\n",
    "&= \\sigma^2DD' + \\sigma^2(X'X)^{-1}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Noten que $DD'$ es un valor positivo.  \n",
    "\n",
    "Por lo tanto:\n",
    "\n",
    "$$\n",
    "Var(b) \\geq Var(\\hat{\\beta}) = \\sigma^2 (X'X)^{-1}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
